{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3KMrksPSkbhD",
        "outputId": "00afbc4a-f2cd-4aef-da83-860b6ead841a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Not connected to a GPU\n"
          ]
        }
      ],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XFRapgXHDX8V",
        "outputId": "69f13b84-afbc-40a5-aaa8-5c1749597209"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.5.2-py3-none-any.whl (432 kB)\n",
            "\u001b[K     |████████████████████████████████| 432 kB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (2022.8.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets) (3.8.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (5.0.0)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n",
            "Collecting multiprocess\n",
            "  Downloading multiprocess-0.70.13-py37-none-any.whl (115 kB)\n",
            "\u001b[K     |████████████████████████████████| 115 kB 51.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n",
            "Collecting huggingface-hub<1.0.0,>=0.2.0\n",
            "  Downloading huggingface_hub-0.10.0-py3-none-any.whl (163 kB)\n",
            "\u001b[K     |████████████████████████████████| 163 kB 49.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.64.1)\n",
            "Requirement already satisfied: dill<0.3.6 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.5.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n",
            "Collecting responses<0.19\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-3.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[K     |████████████████████████████████| 212 kB 52.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.21.6)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.2.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (22.1.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.1.1)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (0.13.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.8.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.1.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.8.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2022.9.24)\n",
            "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 45.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.8.1)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2022.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Installing collected packages: urllib3, xxhash, responses, multiprocess, huggingface-hub, datasets\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "Successfully installed datasets-2.5.2 huggingface-hub-0.10.0 multiprocess-0.70.13 responses-0.18.0 urllib3-1.25.11 xxhash-3.0.0\n",
            "2022-10-10 00:47:55.977830: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting en-core-web-lg==3.4.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.4.0/en_core_web_lg-3.4.0-py3-none-any.whl (587.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 587.7 MB 9.4 kB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy<3.5.0,>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from en-core-web-lg==3.4.0) (3.4.1)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.0) (0.4.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.0) (3.3.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.0) (0.10.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.0) (2.0.8)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.0) (2.11.3)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.0) (3.0.7)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.0) (1.0.8)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.0) (0.6.2)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.0) (3.0.10)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.0) (2.23.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.0) (21.3)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.0) (8.1.2)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.0) (1.0.3)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.0) (1.21.6)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.0) (4.64.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.0) (57.4.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.0) (2.0.6)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.0) (1.9.2)\n",
            "Requirement already satisfied: typing-extensions<4.2.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.0) (4.1.1)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.0) (2.4.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.0) (3.8.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.0) (3.0.9)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.0) (5.2.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.0) (1.25.11)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.0) (2022.9.24)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.7/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.0) (0.7.8)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.7/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.0) (0.0.2)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.0) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.0) (2.0.1)\n",
            "Installing collected packages: en-core-web-lg\n",
            "Successfully installed en-core-web-lg-3.4.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_lg')\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets\n",
        "!python -m spacy download en_core_web_lg\n",
        "import torch\n",
        "import numpy as np\n",
        "import spacy\n",
        "import pandas as pd\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from datasets import load_dataset\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "import time\n",
        "import math\n",
        "from tqdm import tqdm\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aHStV7c7ZPEl",
        "outputId": "f4d517a2-47ff-41e4-b917-93d6fab7f6d3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "b4a11482756b472182a81f5c418e72af",
            "513b1a4b41fd47b3879935517946c785",
            "006484782ba94061a8f72f83404cde81",
            "8fee3868a1554cad869322a25e136477",
            "124914b851fe416da26522f55cbbc673",
            "be911d03968f4d7f97a85b905f4804da",
            "ac5ff9a28e8949218d7b78a168feeb0e",
            "fe79a96de1fe401abfc4f1123e534df4",
            "7d9b9e7cc5bf4129b894a81b69a727e2",
            "4b01f797a65b4a008d3328b54122fc73",
            "4af04500687242d3aa1dc0043e64baf6"
          ]
        },
        "id": "mn9J649-Fx_x",
        "outputId": "bd160c31-ce3f-47b0-8914-e60e9e80cadb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.builder:Using custom data configuration en-fr-lang1=en,lang2=fr\n",
            "WARNING:datasets.builder:Found cached dataset europarl_bilingual (/root/.cache/huggingface/datasets/europarl_bilingual/en-fr-lang1=en,lang2=fr/8.0.0/2ab0200e7729616bfd4a4df6bfb29b31746ceb5a59f8c75c02ca35e1ebead950)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b4a11482756b472182a81f5c418e72af"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "dataset = load_dataset(\"europarl_bilingual\", lang1=\"en\", lang2=\"fr\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "0VNUJcZoKu0j"
      },
      "outputs": [],
      "source": [
        "def process_europarl_corpus(dataset):\n",
        "  en_fr_sents = []\n",
        "  for i,sent in enumerate(dataset[\"train\"][\"translation\"]):\n",
        "    en_fr_sents.append((sent[\"en\"], sent[\"fr\"]))\n",
        "    # if i%1000==0:\n",
        "    #   print(f\"Currently on iteration {i}\")\n",
        "  return en_fr_sents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "pAlZ1lwKGkqw"
      },
      "outputs": [],
      "source": [
        "en_fr_sents = process_europarl_corpus(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Cncwu22yKT9n"
      },
      "outputs": [],
      "source": [
        "en_fr_df = pd.DataFrame(en_fr_sents, columns=[\"en\", \"fr\"])\n",
        "en_fr_df = en_fr_df.loc[:10000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "id": "6pyoJiIlOoOS",
        "outputId": "8ebf62b2-585d-4abd-b6e8-3067daf690c2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                  en  \\\n",
              "0                          Resumption of the session   \n",
              "1  I declare resumed the session of the European ...   \n",
              "2  Although, as you will have seen, the dreaded '...   \n",
              "3  You have requested a debate on this subject in...   \n",
              "4  In the meantime, I should like to observe a mi...   \n",
              "\n",
              "                                                  fr  \n",
              "0                              Reprise de la session  \n",
              "1  Je déclare reprise la session du Parlement eur...  \n",
              "2  Comme vous avez pu le constater, le grand \"bog...  \n",
              "3  Vous avez souhaité un débat à ce sujet dans le...  \n",
              "4  En attendant, je souhaiterais, comme un certai...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-61ef006a-2328-440f-8505-7250362a3e5f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>en</th>\n",
              "      <th>fr</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Resumption of the session</td>\n",
              "      <td>Reprise de la session</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I declare resumed the session of the European ...</td>\n",
              "      <td>Je déclare reprise la session du Parlement eur...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Although, as you will have seen, the dreaded '...</td>\n",
              "      <td>Comme vous avez pu le constater, le grand \"bog...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>You have requested a debate on this subject in...</td>\n",
              "      <td>Vous avez souhaité un débat à ce sujet dans le...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>In the meantime, I should like to observe a mi...</td>\n",
              "      <td>En attendant, je souhaiterais, comme un certai...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-61ef006a-2328-440f-8505-7250362a3e5f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-61ef006a-2328-440f-8505-7250362a3e5f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-61ef006a-2328-440f-8505-7250362a3e5f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "en_fr_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "CHcb8TIGR0VB"
      },
      "outputs": [],
      "source": [
        "nlp = spacy.load(\"en_core_web_lg\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "usxGODfYoTBI"
      },
      "outputs": [],
      "source": [
        "def preprocess(text, nltk_tokenizer):\n",
        "  #cur_sent = \" \".join([\"cls\"] + nltk_tokenizer.tokenize(text.lower()) + [\"sep\"])\n",
        "  cur_sent = \" \".join([\"cls\"] + [x for x in text.split() if x !=\"\"] + [\"sep\"])\n",
        "  return cur_sent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Z81hLgmzonKy"
      },
      "outputs": [],
      "source": [
        "nltk_tokenizer = RegexpTokenizer(r\"[\\w\\d'\\s]+\")\n",
        "en_fr_df[\"en\"] = en_fr_df[\"en\"].apply(lambda x: preprocess(x, nltk_tokenizer))\n",
        "en_fr_df[\"fr\"] = en_fr_df[\"fr\"].apply(lambda x: preprocess(x, nltk_tokenizer))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Y4o8A-0DnE7n"
      },
      "outputs": [],
      "source": [
        "def generate_mappings(en_fr_df, col_name, batch_size=10000):\n",
        "  sents = list(set(en_fr_df[col_name].tolist()))\n",
        "  sents.sort()\n",
        "  latest_token_index = 0\n",
        "  sent_to_tokens = {}\n",
        "  token_to_index = {}\n",
        "  token_vector_list = []\n",
        "  seen_tokens = set()\n",
        "  cls_doc = nlp(\"cls\", disable=[\"parser\",\"ner\"])\n",
        "  seen_tokens.add(cls_doc[0].text)\n",
        "  token_to_index[cls_doc[0].text] = latest_token_index\n",
        "  latest_token_index += 1\n",
        "  token_vector_list.append(torch.Tensor(cls_doc[0].vector))\n",
        "  sep_doc = nlp(\"sep\", disable=[\"parser\",\"ner\"])\n",
        "  seen_tokens.add(sep_doc[0].text)\n",
        "  token_to_index[sep_doc[0].text] = latest_token_index\n",
        "  latest_token_index += 1\n",
        "  token_vector_list.append(torch.Tensor(sep_doc[0].vector))\n",
        "  start_time = time.time()\n",
        "  num_sents = len(sents)\n",
        "  num_batches = math.ceil(num_sents/batch_size)\n",
        "  print(f\"Number of sentences: {num_sents}\")\n",
        "  print(f\"Number of batches: {num_batches}\")\n",
        "  for batch in range(1,num_batches+1):\n",
        "    batch_start_index = (batch-1)*batch_size\n",
        "    docs = nlp.pipe(sents[batch_start_index:min(batch*batch_size, num_sents)], disable=[\"parser\", \"ner\"])\n",
        "    for i,doc in enumerate(docs):\n",
        "      cur_sent_tokens = []\n",
        "      for token in doc:\n",
        "        cur_sent_tokens.append(token)\n",
        "        if token.text not in seen_tokens:\n",
        "          seen_tokens.add(token.text)\n",
        "          token_to_index[token.text] = latest_token_index\n",
        "          latest_token_index += 1\n",
        "          token_vector_list.append(torch.Tensor(token.vector))\n",
        "        sent_to_tokens[sents[batch_start_index+i]] = cur_sent_tokens\n",
        "    end_time = time.time()\n",
        "    total_time = end_time-start_time\n",
        "    print(f\"Total time to finish batch {batch} is: {total_time/60} minutes\")\n",
        "    start_time = time.time()\n",
        "  token_vectors = torch.stack(token_vector_list)\n",
        "  index_to_token = {i:token for token,i in token_to_index.items()}\n",
        "  return sent_to_tokens,token_to_index,index_to_token,token_vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0laeaR5JsRTY",
        "outputId": "f2132ceb-3468-4607-f6e7-d46865ff2507"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of sentences: 9903\n",
            "Number of batches: 1\n",
            "Total time to finish batch 1 is: 0.5529534180959066 minutes\n",
            "Number of sentences: 9902\n",
            "Number of batches: 1\n",
            "Total time to finish batch 1 is: 0.3870299736658732 minutes\n"
          ]
        }
      ],
      "source": [
        "fr_sent_to_tokens,fr_token_to_index,fr_index_to_token,fr_token_vectors = generate_mappings(en_fr_df, \"fr\", batch_size=100000)\n",
        "en_sent_to_tokens,en_token_to_index,en_index_to_token,en_token_vectors = generate_mappings(en_fr_df, \"en\", batch_size=100000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WkaU2xzXVgsn"
      },
      "outputs": [],
      "source": [
        "# x=[i for i in fr_sent_to_tokens.keys() if \"madame\" in i and \"lynne\" in i][0]\n",
        "# print(x)\n",
        "# fr_sent_to_tokens[x]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LnJyvALyOqPn",
        "outputId": "0894b5a6-897a-421b-f43a-a8bc51b061a7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([16478, 300]), 16478, 9903, torch.Size([11651, 300]), 11651, 9902)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "fr_token_vectors.size(),len(fr_token_to_index),len(fr_sent_to_tokens),en_token_vectors.size(),len(en_token_to_index),len(en_sent_to_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Pg0PLaxQ4YD"
      },
      "outputs": [],
      "source": [
        "class MTDataset(Dataset):\n",
        "  def __init__(self,df,max_len,fr_sent_to_tokens,fr_token_to_index,en_sent_to_tokens,en_token_to_index,fr_token_vectors,en_token_vectors):\n",
        "    self.df = df\n",
        "    self.max_len = max_len\n",
        "    self.fr_sent_to_tokens = fr_sent_to_tokens\n",
        "    self.fr_token_to_index = fr_token_to_index\n",
        "    self.en_sent_to_tokens = en_sent_to_tokens\n",
        "    self.en_token_to_index = en_token_to_index\n",
        "    self.fr_token_vectors = fr_token_vectors\n",
        "    self.en_token_vectors = en_token_vectors\n",
        "  def __len__(self):\n",
        "    return len(self.df)\n",
        "  def __getitem__(self, idx):\n",
        "    cur_en_sent = self.df.loc[idx,\"en\"]\n",
        "    cur_fr_sent = self.df.loc[idx,\"fr\"]\n",
        "    cur_en_tokens = self.en_sent_to_tokens[cur_en_sent]\n",
        "    cur_fr_tokens = self.fr_sent_to_tokens[cur_fr_sent]\n",
        "    if (len(cur_en_tokens))>self.max_len or (len(cur_fr_tokens))>self.max_len:\n",
        "      raise Exception(\"The input or target sentence is more than max len tokens\")\n",
        "    inputs = torch.stack([torch.Tensor(self.en_token_vectors[self.en_token_to_index[token.text]]) for token in cur_en_tokens])\n",
        "    targets = torch.stack([torch.Tensor(self.fr_token_vectors[self.fr_token_to_index[token.text]]) for token in cur_fr_tokens[:-1]])\n",
        "    labels = torch.LongTensor([self.fr_token_to_index[token.text] for token in cur_fr_tokens[1:]])\n",
        "    return {\n",
        "        \"inputs\":inputs,\n",
        "        \"targets\": targets,\n",
        "        \"input_seq_len\": torch.LongTensor([len(inputs)]),\n",
        "        \"target_seq_len\": torch.LongTensor([len(targets)]),\n",
        "        \"labels\": labels\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PDPJQ7fX_MhV"
      },
      "outputs": [],
      "source": [
        "def collate_fn(batch):\n",
        "  ignore_index = -1\n",
        "  inputs = nn.utils.rnn.pad_sequence([batch[i][\"inputs\"] for i in range(len(batch))], batch_first=True)\n",
        "  input_seq_lens = torch.stack([batch[i][\"input_seq_len\"] for i in range(len(batch))]).squeeze()\n",
        "  targets = nn.utils.rnn.pad_sequence([batch[i][\"targets\"] for i in range(len(batch))], batch_first=True)\n",
        "  target_seq_lens = torch.stack([batch[i][\"target_seq_len\"] for i in range(len(batch))]).squeeze()\n",
        "  labels = nn.utils.rnn.pad_sequence([batch[i][\"labels\"] for i in range(len(batch))], batch_first=True, padding_value=ignore_index)\n",
        "  return inputs,targets,input_seq_lens,target_seq_lens,labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hHRKbJ6YmjBM"
      },
      "outputs": [],
      "source": [
        "def auto_reg_collate_fn(batch):\n",
        "  max_len=512\n",
        "  ignore_index = -1\n",
        "  inputs = nn.utils.rnn.pad_sequence([batch[i][\"inputs\"] for i in range(len(batch))], batch_first=True)\n",
        "  input_seq_lens = torch.stack([batch[i][\"input_seq_len\"] for i in range(len(batch))]).squeeze()\n",
        "  targets = torch.stack([batch[i][\"targets\"][0] for i in range(len(batch))])\n",
        "  labels = nn.utils.rnn.pad_sequence([batch[i][\"labels\"] for i in range(len(batch))], batch_first=True, padding_value=ignore_index)\n",
        "  ignore_index_vals = torch.full((1,max_len-1-labels.size()[-1]), ignore_index).expand(len(batch), -1)\n",
        "  labels = torch.cat([labels, ignore_index_vals], dim=-1)\n",
        "  return inputs,targets,input_seq_lens,labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HI-zzqU1Si-y"
      },
      "outputs": [],
      "source": [
        "max_len = 512\n",
        "batch_size = 64\n",
        "mtds = MTDataset(en_fr_df,max_len,fr_sent_to_tokens,fr_token_to_index,en_sent_to_tokens,en_token_to_index,fr_token_vectors,en_token_vectors)\n",
        "train_samples = int(0.8*len(mtds))\n",
        "valid_samples = int(0.1*len(mtds))\n",
        "test_samples = len(mtds) - (train_samples+valid_samples)\n",
        "train_ds,valid_ds,test_ds = random_split(mtds, [train_samples, valid_samples, test_samples])\n",
        "train_dataloader = DataLoader(train_ds, batch_size=batch_size, collate_fn=collate_fn)\n",
        "valid_dataloader = DataLoader(valid_ds, batch_size=batch_size, collate_fn=auto_reg_collate_fn)\n",
        "test_dataloader = DataLoader(test_ds, batch_size=batch_size, collate_fn=auto_reg_collate_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NdHkNubt_ccA",
        "outputId": "0b5f9a7e-90c1-4000-b2d2-039cdb6baea1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 83, 300]) torch.Size([64, 300]) torch.Size([64]) torch.Size([64, 511])\n"
          ]
        }
      ],
      "source": [
        "cur_batch = next(iter(valid_dataloader))\n",
        "print(cur_batch[0].size(),cur_batch[1].size(),cur_batch[2].size(),cur_batch[3].size())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2hY-_6jZSn1x",
        "outputId": "01ff8c30-c974-49b6-b882-44c5aadb3ed8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'inputs': tensor([[  0.1240,  -0.0542,   0.1174,  ...,   0.0663,  -0.1964,   0.1107],\n",
              "         [ -9.3107, -10.8970,   1.0395,  ...,   1.5233,   6.7447, -15.8290],\n",
              "         [ -0.7692,  -1.6331,   1.6490,  ...,   0.0795,  -5.9882,   5.2371],\n",
              "         ...,\n",
              "         [ -1.5490,  -0.8127,  -3.4127,  ...,  -4.9873,   1.1062,   3.6366],\n",
              "         [ -0.0765,  -4.6896,  -4.0431,  ...,   1.3040,  -0.5270,  -1.3622],\n",
              "         [ -0.1954,  -1.7745,  -2.6836,  ...,  -2.3685,   0.7443,  -2.5710]]),\n",
              " 'targets': tensor([[ 0.1240, -0.0542,  0.1174,  ...,  0.0663, -0.1964,  0.1107],\n",
              "         [-0.2036, -2.4590,  0.2916,  ...,  2.6948, -0.2805,  0.3046],\n",
              "         [-1.0661, -1.1376, -0.2675,  ..., -0.2280, -1.4617,  2.5464],\n",
              "         ...,\n",
              "         [-1.4330, -2.0019,  0.9980,  ..., -0.7067, -2.3276,  2.4603],\n",
              "         [-0.9714, -0.5238,  0.5012,  ...,  1.1822,  0.1077, -0.1339],\n",
              "         [-0.0765, -4.6896, -4.0431,  ...,  1.3040, -0.5270, -1.3622]]),\n",
              " 'input_seq_len': tensor([16]),\n",
              " 'target_seq_len': tensor([12]),\n",
              " 'labels': tensor([6114,  820,  775,   16,  306,  281,   52, 6703, 1487, 6704,   42,    1])}"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "train_ds[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "67avlJ9dZWn6"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "  def __init__(self, emb_dim, enc_hidden_dim, en_token_vectors, train_emb=False):\n",
        "    super().__init__()\n",
        "    # self.embedding_layer = nn.Embedding.from_pretrained(en_token_vectors)\n",
        "    # if not train_emb:\n",
        "    #   self.embedding_layer.weight.requires_grad = False\n",
        "    self.GRU = nn.GRU(emb_dim, enc_hidden_dim)\n",
        "    self.layernorm_layer = nn.LayerNorm(enc_hidden_dim)\n",
        "  def forward(self, inputs, input_seq_lens):\n",
        "    # x = self.embedding_layer(inputs)\n",
        "    inputs = nn.utils.rnn.pack_padded_sequence(inputs, input_seq_lens.cpu(), batch_first=True, enforce_sorted=False)\n",
        "    outputs, hidden = self.GRU(inputs)\n",
        "    hidden = self.layernorm_layer(hidden)\n",
        "    return outputs, hidden"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uRJxmPzqfRhp"
      },
      "outputs": [],
      "source": [
        "class Decoder(nn.Module):\n",
        "  def __init__(self, emb_dim, enc_hidden_dim, dec_hidden_dim, fr_token_vectors, train_emb=False):\n",
        "    super().__init__()\n",
        "    # self.embedding_layer = nn.Embedding.from_pretrained(fr_token_vectors)\n",
        "    # if not train_emb:\n",
        "    #   self.embedding_layer.weight.requires_grad = False\n",
        "    self.GRU = nn.GRU(emb_dim+enc_hidden_dim, dec_hidden_dim)\n",
        "    self.layernorm_layer = nn.LayerNorm(dec_hidden_dim)\n",
        "    self.dense_layer = nn.Linear(dec_hidden_dim, len(fr_token_vectors))\n",
        "    self.softmax_layer = nn.Softmax(dim=-1)\n",
        "  def forward(self, context_vector, init_hidden_state, targets, target_seq_lens):\n",
        "    # x = self.embedding_layer(targets)\n",
        "    targets_with_context = torch.cat([targets, context_vector.unsqueeze(dim=1).expand(-1, targets.size()[1], -1)], dim=-1)\n",
        "    #print(targets_with_context.size())\n",
        "    targets_with_context = nn.utils.rnn.pack_padded_sequence(targets_with_context, target_seq_lens.cpu(), batch_first=True, enforce_sorted=False)\n",
        "    # print(targets_with_context[0].size(), targets_with_context[1].size(), targets_with_context[0], targets_with_context[1])\n",
        "    # print(\"after pack padded sequence\")\n",
        "    outputs, hidden = self.GRU(targets_with_context, init_hidden_state)\n",
        "    # print(\"after gru\")\n",
        "    outputs, seq_lens = nn.utils.rnn.pad_packed_sequence(outputs, batch_first=True)\n",
        "    # print(outputs.size(),hidden.size(),seq_lens)\n",
        "    outputs = self.layernorm_layer(outputs)\n",
        "    x = self.dense_layer(outputs)\n",
        "    x = self.softmax_layer(x)\n",
        "    return hidden,x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yveiZua88LqS",
        "outputId": "240306ce-82f9-453b-c486-451a29d0a08d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 72, 300]) torch.Size([64, 73, 300]) torch.Size([64]) torch.Size([64]) torch.Size([64, 73])\n",
            "torch.Size([64, 128]) torch.Size([64, 73, 300])\n",
            "torch.Size([1, 64, 128]) torch.Size([64, 16478, 73])\n"
          ]
        }
      ],
      "source": [
        "emb_dim = 300\n",
        "enc_hidden_dim = 128\n",
        "dec_hidden_dim = 128\n",
        "enc = Encoder(emb_dim, enc_hidden_dim, en_token_vectors)\n",
        "dec = Decoder(emb_dim, enc_hidden_dim, dec_hidden_dim, fr_token_vectors)\n",
        "inputs,targets,input_seq_lens,target_seq_lens,labels = next(iter(train_dataloader))\n",
        "print(inputs.size(),targets.size(),input_seq_lens.size(),target_seq_lens.size(),labels.size())\n",
        "_, context = enc(inputs, input_seq_lens)\n",
        "print(context.squeeze().size(), targets.size())\n",
        "hidden_state,decoder_output = dec(context.squeeze(), context, targets, target_seq_lens)\n",
        "decoder_output = decoder_output.permute(0,-1,1)\n",
        "print(hidden_state.size(), decoder_output.size())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EvS0XWEiWKRO",
        "outputId": "c8a4dd14-5ac2-41e4-a147-c39f304406b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<bound method Module.parameters of Encoder(\n",
            "  (GRU): GRU(300, 128)\n",
            "  (layernorm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            ")>\n",
            "<bound method Module.parameters of Decoder(\n",
            "  (GRU): GRU(428, 128)\n",
            "  (layernorm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "  (dense_layer): Linear(in_features=128, out_features=16478, bias=True)\n",
            "  (softmax_layer): Softmax(dim=-1)\n",
            ")>\n"
          ]
        }
      ],
      "source": [
        "emb_dim = 300\n",
        "enc_hidden_dim = 128\n",
        "dec_hidden_dim = 128\n",
        "enc = Encoder(emb_dim, enc_hidden_dim, en_token_vectors)\n",
        "dec = Decoder(emb_dim, enc_hidden_dim, dec_hidden_dim, fr_token_vectors)\n",
        "enc.to(device)\n",
        "dec.to(device)\n",
        "loss_fn = nn.CrossEntropyLoss(ignore_index=-1)\n",
        "encoder_optimizer = optim.Adam(enc.parameters(), lr=1e-3)\n",
        "decoder_optimizer = optim.Adam(dec.parameters(), lr=1e-3)\n",
        "print(enc.parameters)\n",
        "print(dec.parameters)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DoHr7blTUb7A",
        "outputId": "3aa97ff8-1d82-46f2-f1a1-e6b32b92f4bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of batches: 125.0\n",
            "EPOCH 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 90%|████████▉ | 112/125 [12:58<01:29,  6.87s/it]"
          ]
        }
      ],
      "source": [
        "if os.path.exists(\"/content/sample_data/log.txt\"):\n",
        "    os.remove(\"/content/sample_data/log.txt\")\n",
        "teacher_forcing = True\n",
        "epochs = 10\n",
        "print(f\"number of batches: {len(train_ds)/batch_size}\")\n",
        "train_losses = []\n",
        "valid_losses = []\n",
        "min_valid_epoch_loss = float(\"inf\")\n",
        "for epoch_num in range(epochs):\n",
        "  print(f\"EPOCH {epoch_num}\")\n",
        "  running_loss = 0\n",
        "  loss = 0\n",
        "  batch_num = 0\n",
        "  epoch_start_time = time.time()\n",
        "  batch_start_time = time.time()\n",
        "  cur_batch_start_time = time.time()\n",
        "  enc.train()\n",
        "  dec.train()\n",
        "  for batch_num,batch in enumerate(tqdm(train_dataloader)):\n",
        "    inputs,targets,input_seq_lens,target_seq_lens,labels = next(iter(train_dataloader))\n",
        "    inputs = inputs.to(device)\n",
        "    targets = targets.to(device)\n",
        "    input_seq_lens = input_seq_lens.to(device)\n",
        "    target_seq_lens = target_seq_lens.to(device)\n",
        "    labels = labels.to(device)\n",
        "    _, context = enc(inputs, input_seq_lens)\n",
        "    hidden_state,decoder_output = dec(context.squeeze(dim=0), context, targets, target_seq_lens)\n",
        "    decoder_output = decoder_output.permute(0,-1,1)\n",
        "    loss = loss_fn(decoder_output, labels)\n",
        "    loss.backward()\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "    if batch_num%500==0:\n",
        "        batch_end_time = time.time()\n",
        "        batch_total_time = batch_end_time-batch_start_time\n",
        "        # print(f\"BATCH_END,epoch:{epoch_num},batch:{batch_num},loss:{loss},time:{batch_total_time/60}\")\n",
        "        # print(decoder_output.size(),labels.size())\n",
        "        with open(\"/content/sample_data/log.txt\", \"a+\") as f:\n",
        "          f.write(f\"BATCH_END,epoch:{epoch_num},batch:{batch_num},loss:{loss},time:{batch_total_time/60}\\n\")\n",
        "        batch_start_time = time.time()\n",
        "    #print(f\"Finished batch {batch_num} in time {(time.time()-cur_batch_start_time)/60} minutes\")\n",
        "    cur_batch_start_time = time.time()\n",
        "    running_loss += loss\n",
        "  train_epoch_loss = running_loss/len(train_dataloader)\n",
        "  train_losses.append(train_epoch_loss)\n",
        "  epoch_end_time = time.time()\n",
        "  epoch_total_time = epoch_end_time-epoch_start_time\n",
        "  print(f\"EPOCH_END,epoch:{epoch_num},loss:{train_epoch_loss},time:{epoch_total_time/60}\")\n",
        "  with open(\"/content/sample_data/log.txt\", \"a+\") as f:\n",
        "    f.write(f\"EPOCH_END,epoch:{epoch_num},loss:{train_epoch_loss},time:{epoch_total_time/60}\\n\")\n",
        "  with torch.no_grad():\n",
        "    enc.eval()\n",
        "    dec.eval()\n",
        "    print(\"Running Validation...\")\n",
        "    running_loss = 0\n",
        "    epoch_start_time = time.time()\n",
        "    for batch_num,batch in enumerate(tqdm(valid_dataloader)):\n",
        "      inputs,targets,input_seq_lens,labels = batch\n",
        "      inputs = inputs.to(device)\n",
        "      targets = targets.to(device)\n",
        "      input_seq_lens = input_seq_lens.to(device)\n",
        "      labels = labels.to(device)\n",
        "      _, context = enc(inputs, input_seq_lens)\n",
        "      decoder_final_outputs = []\n",
        "      for decoder_start_index in range(len(targets)):\n",
        "        num_decoder_output_tokens = 1\n",
        "        cur_predicted_token = None\n",
        "        cur_context_vector = context[:,decoder_start_index,:].unsqueeze(dim=1)\n",
        "        decoder_start_vector = targets[decoder_start_index].unsqueeze(0).unsqueeze(0)\n",
        "        cur_input_vector = decoder_start_vector\n",
        "        prev_hidden_state = cur_context_vector\n",
        "        decoder_sequence_outputs = []\n",
        "        while cur_predicted_token!=\"sep\" and num_decoder_output_tokens<max_len:\n",
        "          hidden_state,decoder_output = dec(cur_context_vector.squeeze(dim=0), prev_hidden_state, cur_input_vector, torch.LongTensor([1]))\n",
        "          cur_predicted_token_index = int(torch.argmax(decoder_output[0,0,:]))\n",
        "          cur_predicted_token = fr_index_to_token[cur_predicted_token_index]\n",
        "          prev_hidden_state = hidden_state\n",
        "          cur_input_vector = fr_token_vectors[cur_predicted_token_index].unsqueeze(0).unsqueeze(0)\n",
        "          cur_input_vector.to(device)\n",
        "          num_decoder_output_tokens += 1\n",
        "          decoder_sequence_outputs.append(decoder_output)\n",
        "        decoder_sequence_output = torch.cat(decoder_sequence_outputs, dim=1)\n",
        "        pad_matrix = torch.full((1,max_len-num_decoder_output_tokens,decoder_sequence_output.size()[-1]), 0)\n",
        "        decoder_sequence_output = torch.cat([decoder_sequence_output,pad_matrix], dim=1)\n",
        "        decoder_final_outputs.append(decoder_sequence_output)\n",
        "      decoder_final_output = torch.cat(decoder_final_outputs, dim=0)\n",
        "      decoder_final_output = decoder_final_output.permute(0,-1,1)\n",
        "      running_loss += loss_fn(decoder_final_output, labels)\n",
        "    valid_epoch_loss = running_loss/len(valid_dataloader)\n",
        "    valid_losses.append(valid_epoch_loss)\n",
        "    if valid_epoch_loss < min_valid_epoch_loss:\n",
        "      min_valid_epoch_loss = valid_epoch_loss\n",
        "      print(f\"Saving model after training epoch {epoch_num} with loss {min_valid_epoch_loss}...\")\n",
        "      with open(\"/content/sample_data/log.txt\", \"a+\") as f:\n",
        "        f.write(f\"Saving model after training epoch {epoch_num} with loss {min_valid_epoch_loss}...\\n\")\n",
        "      torch.save(enc.state_dict(), f\"/content/sample_data/best_enc_{epoch_num}_{min_valid_epoch_loss}.bin\")\n",
        "      torch.save(dec.state_dict(), f\"/content/sample_data/best_dec_{epoch_num}_{min_valid_epoch_loss}.bin\")\n",
        "    epoch_end_time = time.time()\n",
        "    epoch_total_time = epoch_end_time-epoch_start_time\n",
        "    print(f\"VALID_EPOCH_END,loss:{valid_epoch_loss},time:{epoch_total_time/60}\")\n",
        "    with open(\"/content/sample_data/log.txt\", \"a+\") as f:\n",
        "      f.write(f\"VALID_EPOCH_END,loss:{valid_epoch_loss},time:{epoch_total_time/60}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t_7Wu8AaqNl_",
        "outputId": "89276766-ad39-49ac-a419-05cb8891a95f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|█████     | 1/2 [00:21<00:21, 21.91s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 511, 4648]) torch.Size([64, 511])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:34<00:00, 17.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([36, 511, 4648]) torch.Size([36, 511])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "print(len(valid_ds), len(valid_dataloader))\n",
        "with torch.no_grad():\n",
        "    enc.eval()\n",
        "    dec.eval()\n",
        "    for batch_num,batch in enumerate(tqdm(valid_dataloader)):\n",
        "      inputs,targets,input_seq_lens,labels = batch\n",
        "      inputs = inputs.to(device)\n",
        "      targets = targets.to(device)\n",
        "      input_seq_lens = input_seq_lens.to(device)\n",
        "      labels = labels.to(device)\n",
        "      _, context = enc(inputs, input_seq_lens)\n",
        "      decoder_final_outputs = []\n",
        "      for decoder_start_index in range(len(targets)):\n",
        "        num_decoder_output_tokens = 1\n",
        "        cur_predicted_token = None\n",
        "        cur_context_vector = context[:,decoder_start_index,:].unsqueeze(dim=1)\n",
        "        decoder_start_vector = targets[decoder_start_index].unsqueeze(0).unsqueeze(0)\n",
        "        cur_input_vector = decoder_start_vector\n",
        "        prev_hidden_state = cur_context_vector\n",
        "        decoder_sequence_outputs = []\n",
        "        while cur_predicted_token!=\"sep\" and num_decoder_output_tokens<max_len:\n",
        "          hidden_state,decoder_output = dec(cur_context_vector.squeeze(dim=0), prev_hidden_state, cur_input_vector, torch.LongTensor([1]))\n",
        "          cur_predicted_token_index = int(torch.argmax(decoder_output[0,0,:]))\n",
        "          cur_predicted_token = fr_index_to_token[cur_predicted_token_index]\n",
        "          prev_hidden_state = hidden_state\n",
        "          cur_input_vector = fr_token_vectors[cur_predicted_token_index].unsqueeze(0).unsqueeze(0)\n",
        "          cur_input_vector.to(device)\n",
        "          num_decoder_output_tokens += 1\n",
        "          decoder_sequence_outputs.append(decoder_output)\n",
        "        decoder_sequence_output = torch.cat(decoder_sequence_outputs, dim=1)\n",
        "        pad_matrix = torch.full((1,max_len-num_decoder_output_tokens,decoder_sequence_output.size()[-1]), 0)\n",
        "        decoder_sequence_output = torch.cat([decoder_sequence_output,pad_matrix], dim=1)\n",
        "        decoder_final_outputs.append(decoder_sequence_output)\n",
        "      decoder_final_output = torch.cat(decoder_final_outputs, dim=0)\n",
        "      print(decoder_final_output.size(), labels.size())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "id": "xzzM_wZxHbpt",
        "outputId": "6b4bfc38-4e4d-4645-fef7-4776eee1ea11"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "number of batches: 1875.0\n",
            "End of batch 0, current loss is 11.211583137512207, total time taken: 0.00957711140314738\n",
            "End of batch 100, current loss is 11.079082489013672, total time taken: 0.7673563559850057\n",
            "End of batch 200, current loss is 11.04337215423584, total time taken: 1.5181862950325011\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-119-e0bb839e4e4a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m#print(inputs, target_ids, labels)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;31m#print(\"===========\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0mhidden_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdecoder_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;31m#print(\"=======================\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-104-80c6920f8793>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# x = self.embedding_layer(inputs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGRU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayernorm_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    949\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m             result = _VF.gru(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0;32m--> 951\u001b[0;31m                              self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[1;32m    952\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    953\u001b[0m             result = _VF.gru(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "teacher_forcing = True\n",
        "epochs = 10\n",
        "batch_size = 128\n",
        "print(f\"number of batches: {len(train_ds)/batch_size}\")\n",
        "for epoch in range(epochs):\n",
        "  encoder_optimizer.zero_grad()\n",
        "  decoder_optimizer.zero_grad()\n",
        "  running_loss = 0\n",
        "  loss = 0\n",
        "  batch_num = 0\n",
        "  epoch_start_time = time.time()\n",
        "  batch_start_time = time.time()\n",
        "  cur_batch_start_time = time.time()\n",
        "  for i in range(len(train_ds)):\n",
        "    inputs = train_ds[i]['inputs']\n",
        "    targets = train_ds[i]['targets']\n",
        "    labels = train_ds[i]['labels']\n",
        "    inputs = inputs.to(device)\n",
        "    targets = targets.to(device)\n",
        "    labels = labels.to(device)\n",
        "    #print(inputs, target_ids, labels)\n",
        "    #print(\"===========\")\n",
        "    _, context = enc(inputs)\n",
        "    hidden_state,decoder_output = dec(context, context, targets)\n",
        "    #print(\"=======================\")\n",
        "    #print(decoder_outputs.size(), labels.size())\n",
        "    #print(target_ids, torch.argmax(decoder_outputs, dim=-1),  labels)\n",
        "    #print(\"=======================\")\n",
        "    #print(decoder_outputs.size(), labels.size())\n",
        "    # if i % 1000==0:\n",
        "    #   print(torch.gather(decoder_outputs, -1, labels.unsqueeze(dim=-1)))\n",
        "    loss += loss_fn(decoder_output, labels)\n",
        "    #loss.backward()\n",
        "    # print(\"========BEFORE STEP\")\n",
        "    # print(enc.GRU.weight_ih_l0[280,50], enc.GRU.weight_ih_l0.grad[280,50])\n",
        "    # print(dec.GRU.weight_ih_l0[280,50], dec.GRU.weight_ih_l0.grad[280,50])\n",
        "    # if i%1000==0:\n",
        "    #   print(hidden_state)\n",
        "    # max_grad = torch.max(dec.dense_layer.weight.grad)\n",
        "    # max_grad_pos = (dec.dense_layer.weight.grad==max_grad).nonzero()\n",
        "    # max_grad_x = int(max_grad_pos[0][0])\n",
        "    # max_grad_y = int(max_grad_pos[0][1])\n",
        "    # print(dec.dense_layer.weight[max_grad_x,max_grad_y],dec.dense_layer.weight.grad[max_grad_x,max_grad_y], max_grad, max_grad_pos[0])\n",
        "    # encoder_optimizer.step()\n",
        "    # decoder_optimizer.step()\n",
        "    # print(\"========AFTER STEP\")\n",
        "    # print(enc.GRU.weight_ih_l0[280,50], enc.GRU.weight_ih_l0.grad[280,50])\n",
        "    # print(dec.GRU.weight_ih_l0[280,50], dec.GRU.weight_ih_l0.grad[280,50])\n",
        "    # print(dec.dense_layer.weight[max_grad_x,max_grad_y],dec.dense_layer.weight.grad[max_grad_x,max_grad_y], max_grad, max_grad_pos[0])\n",
        "    if (i+1) % batch_size == 0:\n",
        "      running_loss += loss\n",
        "      loss.backward()\n",
        "      # print(\"========BEFORE STEP\")\n",
        "      # print(enc.GRU.weight_ih_l0[280,50], enc.GRU.weight_ih_l0.grad[280,50])\n",
        "      # print(dec.GRU.weight_ih_l0[280,50], dec.GRU.weight_ih_l0.grad[280,50])\n",
        "      encoder_optimizer.step()\n",
        "      decoder_optimizer.step()\n",
        "      # print(\"========AFTER STEP\")\n",
        "      # print(enc.GRU.weight_ih_l0[280,50], enc.GRU.weight_ih_l0.grad[280,50])\n",
        "      # print(dec.GRU.weight_ih_l0[280,50], dec.GRU.weight_ih_l0.grad[280,50])\n",
        "      encoder_optimizer.zero_grad()\n",
        "      decoder_optimizer.zero_grad()\n",
        "      if batch_num%100==0:\n",
        "        batch_end_time = time.time()\n",
        "        batch_total_time = batch_end_time-batch_start_time\n",
        "        print(f\"End of batch {batch_num}, current loss is {loss/batch_size}, total time taken: {batch_total_time/60}\")\n",
        "      # print(f\"Finished batch {batch_num} in time {(time.time()-cur_batch_start_time)/60} minutes\")\n",
        "      cur_batch_start_time = time.time()\n",
        "      loss = 0\n",
        "      batch_num +=1\n",
        "  running_loss += loss\n",
        "  loss.backward()\n",
        "  encoder_optimizer.step()\n",
        "  decoder_optimizer.step()\n",
        "  epoch_end_time = time.time()\n",
        "  epoch_total_time = epoch_end_time-epoch_start_time\n",
        "  print(f\"End of epoch {epoch}, current loss is {running_loss/len(train_ds)}, total time taken: {epoch_total_time/60}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        },
        "id": "xCOr6FOfciSv",
        "outputId": "394bc5c3-d6aa-4794-df4b-0f666844add6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "number of batches: 937.5\n",
            "End of batch 0, current loss is 11.209644317626953, total time taken: 0.16027901967366537\n",
            "Finished batch 0 in time 0.1602869470914205 minutes\n",
            "Finished batch 1 in time 0.1357125719388326 minutes\n",
            "Finished batch 2 in time 0.1436716914176941 minutes\n",
            "Finished batch 3 in time 0.14378207127253215 minutes\n",
            "Finished batch 4 in time 0.15283559958140056 minutes\n",
            "Finished batch 5 in time 0.14501917362213135 minutes\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-81-09ebfcd3aa50>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m       \u001b[0mcur_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m       \u001b[0mhidden_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdecoder_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprev_hidden_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m       \u001b[0mprev_hidden_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m       \u001b[0mprev_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-78-1e1c2a2787d2>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, context_vector, init_hidden_state, targets)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mtargets_with_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext_vector\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGRU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargets_with_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_hidden_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayernorm_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    949\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m             result = _VF.gru(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0;32m--> 951\u001b[0;31m                              self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[1;32m    952\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    953\u001b[0m             result = _VF.gru(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "teacher_forcing = True\n",
        "epochs = 10\n",
        "batch_size = 256\n",
        "print(f\"number of batches: {len(train_ds)/batch_size}\")\n",
        "for epoch in range(epochs):\n",
        "  encoder_optimizer.zero_grad()\n",
        "  decoder_optimizer.zero_grad()\n",
        "  running_loss = 0\n",
        "  loss = 0\n",
        "  batch_num = 0\n",
        "  epoch_start_time = time.time()\n",
        "  batch_start_time = time.time()\n",
        "  cur_batch_start_time = time.time()\n",
        "  for i in range(len(train_ds)):\n",
        "    inputs = train_ds[i]['input_ids']\n",
        "    target_ids = train_ds[i]['target_ids']\n",
        "    labels = train_ds[i]['labels']\n",
        "    inputs = inputs.to(device)\n",
        "    target_ids = target_ids.to(device)\n",
        "    labels = labels.to(device)\n",
        "    #print(inputs, target_ids, labels)\n",
        "    #print(\"===========\")\n",
        "    _, context = enc(inputs)\n",
        "    prev_hidden_state = context\n",
        "    prev_label = None\n",
        "    decoder_outputs = []\n",
        "    for j in range(len(target_ids)):\n",
        "      cur_label = torch.Tensor(target_ids[j])\n",
        "      hidden_state,decoder_output = dec(context, prev_hidden_state, cur_label)\n",
        "      prev_hidden_state = hidden_state\n",
        "      prev_label = torch.argmax(decoder_output)\n",
        "      decoder_outputs.append(decoder_output)\n",
        "    decoder_outputs = torch.cat(decoder_outputs, dim=0)\n",
        "    #print(\"=======================\")\n",
        "    #print(decoder_outputs.size(), labels.size())\n",
        "    #print(target_ids, torch.argmax(decoder_outputs, dim=-1),  labels)\n",
        "    #print(\"=======================\")\n",
        "    #print(decoder_outputs.size(), labels.size())\n",
        "    # if i % 1000==0:\n",
        "    #   print(torch.gather(decoder_outputs, -1, labels.unsqueeze(dim=-1)))\n",
        "    loss += loss_fn(decoder_outputs, labels)\n",
        "    #loss.backward()\n",
        "    # print(\"========BEFORE STEP\")\n",
        "    # print(enc.GRU.weight_ih_l0[280,50], enc.GRU.weight_ih_l0.grad[280,50])\n",
        "    # print(dec.GRU.weight_ih_l0[280,50], dec.GRU.weight_ih_l0.grad[280,50])\n",
        "    # if i%1000==0:\n",
        "    #   print(hidden_state)\n",
        "    # max_grad = torch.max(dec.dense_layer.weight.grad)\n",
        "    # max_grad_pos = (dec.dense_layer.weight.grad==max_grad).nonzero()\n",
        "    # max_grad_x = int(max_grad_pos[0][0])\n",
        "    # max_grad_y = int(max_grad_pos[0][1])\n",
        "    # print(dec.dense_layer.weight[max_grad_x,max_grad_y],dec.dense_layer.weight.grad[max_grad_x,max_grad_y], max_grad, max_grad_pos[0])\n",
        "    # encoder_optimizer.step()\n",
        "    # decoder_optimizer.step()\n",
        "    # print(\"========AFTER STEP\")\n",
        "    # print(enc.GRU.weight_ih_l0[280,50], enc.GRU.weight_ih_l0.grad[280,50])\n",
        "    # print(dec.GRU.weight_ih_l0[280,50], dec.GRU.weight_ih_l0.grad[280,50])\n",
        "    # print(dec.dense_layer.weight[max_grad_x,max_grad_y],dec.dense_layer.weight.grad[max_grad_x,max_grad_y], max_grad, max_grad_pos[0])\n",
        "    if (i+1) % batch_size == 0:\n",
        "      running_loss += loss\n",
        "      loss.backward()\n",
        "      # print(\"========BEFORE STEP\")\n",
        "      # print(enc.GRU.weight_ih_l0[280,50], enc.GRU.weight_ih_l0.grad[280,50])\n",
        "      # print(dec.GRU.weight_ih_l0[280,50], dec.GRU.weight_ih_l0.grad[280,50])\n",
        "      encoder_optimizer.step()\n",
        "      decoder_optimizer.step()\n",
        "      # print(\"========AFTER STEP\")\n",
        "      # print(enc.GRU.weight_ih_l0[280,50], enc.GRU.weight_ih_l0.grad[280,50])\n",
        "      # print(dec.GRU.weight_ih_l0[280,50], dec.GRU.weight_ih_l0.grad[280,50])\n",
        "      encoder_optimizer.zero_grad()\n",
        "      decoder_optimizer.zero_grad()\n",
        "      if batch_num%100==0:\n",
        "        batch_end_time = time.time()\n",
        "        batch_total_time = batch_end_time-batch_start_time\n",
        "        print(f\"End of batch {batch_num}, current loss is {loss/batch_size}, total time taken: {batch_total_time/60}\")\n",
        "      print(f\"Finished batch {batch_num} in time {(time.time()-cur_batch_start_time)/60} minutes\")\n",
        "      cur_batch_start_time = time.time()\n",
        "      loss = 0\n",
        "      batch_num +=1\n",
        "  running_loss += loss\n",
        "  loss.backward()\n",
        "  encoder_optimizer.step()\n",
        "  decoder_optimizer.step()\n",
        "  epoch_end_time = time.time()\n",
        "  epoch_total_time = epoch_end_time-epoch_start_time\n",
        "  print(f\"End of epoch {epoch}, current loss is {running_loss/len(train_ds)}, total time taken: {epoch_total_time/60}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Cjjo8RxBU5n"
      },
      "outputs": [],
      "source": [
        "class LuongAttnDecoder(nn.Module):\n",
        "  def __init__(self, emb_dim, enc_hidden_dim, dec_hidden_dim, fr_token_vectors, train_emb=False):\n",
        "    super().__init__()\n",
        "    self.embedding_layer = nn.Embedding.from_pretrained(fr_token_vectors)\n",
        "    if not train_emb:\n",
        "      self.embedding_layer.weight.requires_grad = False\n",
        "    self.GRU = nn.GRU(emb_dim, dec_hidden_dim)\n",
        "    self.dense_layer = nn.Linear(dec_hidden_dim+enc_hidden_dim, len(fr_token_vectors))\n",
        "    self.attn = nn.Linear(enc_hidden_dim, enc_hidden_dim)\n",
        "    self.softmax_layer = nn.Softmax(dim=-1)\n",
        "  def forward(self, context_vectors, init_hidden_state, targets):\n",
        "    x = self.embedding_layer(targets)\n",
        "    _, hidden = self.GRU(x.unsqueeze(dim=0), init_hidden_state)\n",
        "    context_vector_lin_out = self.attn(context_vectors)\n",
        "    alignment_scores = context_vector_lin_out @ hidden.T\n",
        "    context_vector = alignment_scores.T @ context_vectors\n",
        "    x = torch.tanh(self.dense_layer(torch.cat([context_vector, hidden], dim=1)))\n",
        "    x = self.softmax_layer(x)\n",
        "    return hidden,x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TCz3cecmXeF4"
      },
      "outputs": [],
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "  def __init__(self,emb_dim,n_heads):\n",
        "    super().__init__()\n",
        "    self.emb_dim = emb_dim\n",
        "    self.n_heads = n_heads\n",
        "    self.heads = []\n",
        "    self.head_size = self.emb_dim/self.n_heads\n",
        "    for i in torch.range(self.n_heads):\n",
        "      cur_heads = [nn.Linear(self.emb_dim,self.head_size)]*3\n",
        "      self.heads.append(cur_heads)\n",
        "    self.softmax_layer = nn.Softmax(dim=-1)\n",
        "    self.output_linear_layer = nn.Linear(emb_dim,emb_dim)\n",
        "  def forward(self, Q, K, V, attn_mask):\n",
        "    head_outputs = []\n",
        "    for head in self.heads:\n",
        "      Q_attn = self.head[0](Q)\n",
        "      K_attn = self.head[1](K)\n",
        "      V_attn = self.head[2](V)\n",
        "      attn_scores = self.softmax_layer(((Q_attn @ K_attn.T) + attn_mask)/torch.sqrt(Q.size()[-1]))\n",
        "      head_output = attn_scores @ V_attn\n",
        "      head_outputs.append(head_output)\n",
        "    head_result = torch.cat(head_outputs, dim=-1)\n",
        "    x = self.output_linear_layer(head_result)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oDFuDJyjcDVt"
      },
      "outputs": [],
      "source": [
        "class PosEncoding(nn.Module):\n",
        "  def __init__(self, n, d):\n",
        "    super().__init__()\n",
        "    self.n = n\n",
        "    self.d = d\n",
        "  def pos_encoding_denom(self,i):\n",
        "    return self.n**(2*i/self.d)\n",
        "  def forward(self, inputs):\n",
        "    x_k = torch.arange(inputs.size()[0]).unsqueeze(dim=-1)\n",
        "    x_k = x_k.expand(-1,self.emb_dim)\n",
        "    x_i = torch.arange(inputs.size()[1]).unsqueeze(dim=0)\n",
        "    x_i = torch.Tensor(list(map(self.pos_encoding_denom, torch.arange(inputs.size()[1])))).unsqueeze(dim=0)\n",
        "    x_i = x_i.expand(inputs.size()[0],-1)\n",
        "    x_pos = x_k/x_i\n",
        "    even_indices = torch.arange(0,inputs.size()[1], step=2)\n",
        "    odd_indices = torch.arange(1,inputs.size()[1], step=2)\n",
        "    x_pos[:,even_indices] = torch.sin(x_pos[:,even_indices])\n",
        "    x_pos[:,odd_indices] = torch.cos(x_pos[:,odd_indices])\n",
        "    return inputs+x_pos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T9X9x7qAM27j"
      },
      "outputs": [],
      "source": [
        "class AttnEncoder(nn.Module):\n",
        "  def __init__(self, emb_dim):\n",
        "    super().__init__()\n",
        "    self.emb_dim = emb_dim\n",
        "    self.pos_encoding = PosEncoding(10000,emb_dim)\n",
        "    self.multi_head_attn = nn.MultiheadAttention(emb_dim, 3)\n",
        "    self.layer_norm1 = nn.LayerNorm(emb_dim)\n",
        "    self.linear_layer = nn.Linear(emb_dim, emb_dim)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.layer_norm2 = nn.LayerNorm(emb_dim)\n",
        "  def forward(self, inputs):\n",
        "    inputs = self.pos_encoding(inputs)\n",
        "    x = self.multi_head_attn(inputs, inputs, inputs)[0]\n",
        "    x = self.layer_norm1(inputs+x)\n",
        "    linear_output = self.linear_layer(x)\n",
        "    feed_forward_output = self.relu(linear_output)\n",
        "    x = self.layer_norm2(feed_forward_output+x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        },
        "id": "vkuYARnbb37O",
        "outputId": "dbca9df2-893b-43ee-8cf7-ee7552c43976"
      },
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-65-bdf39958fd34>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    def __init__(self, ):\u001b[0m\n\u001b[0m                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
          ]
        }
      ],
      "source": [
        "class AttnDecoder(nn.Module):\n",
        "  def __init__(self, emb_dim, encoder_output):\n",
        "    self.emb_dim = emb_dim\n",
        "    self.encoder_output = encoder_output\n",
        "    self.pos_encoding = PosEncoding(10000,emb_dim)\n",
        "    self.masked_multi_head_attn = nn.MultiheadAttention(emb_dim, 3)\n",
        "    self.layer_norm1 = nn.LayerNorm(emb_dim)\n",
        "    self.encoder_decoder_attn = nn.MultiheadAttention(emb_dim, 3)\n",
        "    self.layer_norm2 = nn.LayerNorm(emb_dim)\n",
        "    self.linear_layer1 = nn.Linear(emb_dim, emb_dim)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.layer_norm3 = nn.LayerNorm(emb_dim)\n",
        "    self.linear_layer2 = nn.Linear(emb_dim)\n",
        "  def forward(self, inputs, attn_mask, timestep):\n",
        "    inputs = self.pos_encoding(inputs)\n",
        "    \n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "unFsAGeyS6X9",
        "outputId": "764f2bce-23c5-4d85-bf93-36fbcbd86715"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([10, 300])\n"
          ]
        }
      ],
      "source": [
        "attn_enc = AttnEncoder(300)\n",
        "x = attn_enc(torch.randn(10,300))\n",
        "print(x.size())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZHce0qHXEHdz",
        "outputId": "0e9a7093-59ae-481b-ca1c-0d6217855a1a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 896])\n"
          ]
        }
      ],
      "source": [
        "emb_dim = 300\n",
        "enc_hidden_dim = 128\n",
        "dec_hidden_dim = 128\n",
        "enc = Encoder(emb_dim, enc_hidden_dim, en_token_vectors)\n",
        "dec = LuongAttnDecoder(emb_dim, enc_hidden_dim, dec_hidden_dim, fr_token_vectors)\n",
        "for i in range(1):\n",
        "    inputs = train_ds[i]['input_ids']\n",
        "    target_ids = train_ds[i]['target_ids']\n",
        "    labels = train_ds[i]['labels']\n",
        "    inputs = inputs.to(device)\n",
        "    target_ids = target_ids.to(device)\n",
        "    labels = labels.to(device)\n",
        "    outputs, context = enc(inputs)\n",
        "    prev_hidden_state = context\n",
        "    prev_label = None\n",
        "    decoder_outputs = []\n",
        "    for j in range(1):\n",
        "      cur_label = torch.Tensor(target_ids[j])\n",
        "      hidden_state,decoder_output = dec(outputs, prev_hidden_state, cur_label)\n",
        "      print(decoder_output.size())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O8OO0Ok2bytY"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b4a11482756b472182a81f5c418e72af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_513b1a4b41fd47b3879935517946c785",
              "IPY_MODEL_006484782ba94061a8f72f83404cde81",
              "IPY_MODEL_8fee3868a1554cad869322a25e136477"
            ],
            "layout": "IPY_MODEL_124914b851fe416da26522f55cbbc673"
          }
        },
        "513b1a4b41fd47b3879935517946c785": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_be911d03968f4d7f97a85b905f4804da",
            "placeholder": "​",
            "style": "IPY_MODEL_ac5ff9a28e8949218d7b78a168feeb0e",
            "value": "100%"
          }
        },
        "006484782ba94061a8f72f83404cde81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fe79a96de1fe401abfc4f1123e534df4",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7d9b9e7cc5bf4129b894a81b69a727e2",
            "value": 1
          }
        },
        "8fee3868a1554cad869322a25e136477": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4b01f797a65b4a008d3328b54122fc73",
            "placeholder": "​",
            "style": "IPY_MODEL_4af04500687242d3aa1dc0043e64baf6",
            "value": " 1/1 [00:00&lt;00:00, 14.84it/s]"
          }
        },
        "124914b851fe416da26522f55cbbc673": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be911d03968f4d7f97a85b905f4804da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac5ff9a28e8949218d7b78a168feeb0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fe79a96de1fe401abfc4f1123e534df4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d9b9e7cc5bf4129b894a81b69a727e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4b01f797a65b4a008d3328b54122fc73": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4af04500687242d3aa1dc0043e64baf6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}