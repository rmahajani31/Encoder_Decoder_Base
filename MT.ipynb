{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3KMrksPSkbhD",
    "outputId": "00afbc4a-f2cd-4aef-da83-860b6ead841a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: line 1: nvidia-smi: command not found\n"
     ]
    }
   ],
   "source": [
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "if gpu_info.find('failed') >= 0:\n",
    "  print('Not connected to a GPU')\n",
    "else:\n",
    "  print(gpu_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XFRapgXHDX8V",
    "outputId": "69f13b84-afbc-40a5-aaa8-5c1749597209"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import spacy\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from datasets import load_dataset\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import time\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aHStV7c7ZPEl",
    "outputId": "f4d517a2-47ff-41e4-b917-93d6fab7f6d3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "CHcb8TIGR0VB"
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Below is the code to generate data once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104,
     "referenced_widgets": [
      "b4a11482756b472182a81f5c418e72af",
      "513b1a4b41fd47b3879935517946c785",
      "006484782ba94061a8f72f83404cde81",
      "8fee3868a1554cad869322a25e136477",
      "124914b851fe416da26522f55cbbc673",
      "be911d03968f4d7f97a85b905f4804da",
      "ac5ff9a28e8949218d7b78a168feeb0e",
      "fe79a96de1fe401abfc4f1123e534df4",
      "7d9b9e7cc5bf4129b894a81b69a727e2",
      "4b01f797a65b4a008d3328b54122fc73",
      "4af04500687242d3aa1dc0043e64baf6"
     ]
    },
    "id": "mn9J649-Fx_x",
    "outputId": "bd160c31-ce3f-47b0-8914-e60e9e80cadb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration en-fr-lang1=en,lang2=fr\n",
      "Reusing dataset europarl_bilingual (/home/rmahajani31/.cache/huggingface/datasets/europarl_bilingual/en-fr-lang1=en,lang2=fr/8.0.0/2ab0200e7729616bfd4a4df6bfb29b31746ceb5a59f8c75c02ca35e1ebead950)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df84b24d910b4600b2494aecd2a543bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"europarl_bilingual\", lang1=\"en\", lang2=\"fr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "0VNUJcZoKu0j"
   },
   "outputs": [],
   "source": [
    "def process_europarl_corpus(dataset):\n",
    "    en_fr_sents = []\n",
    "    for i,sent in enumerate(dataset[\"train\"][\"translation\"]):\n",
    "        en_fr_sents.append((sent[\"en\"], sent[\"fr\"]))\n",
    "    # if i%1000==0:\n",
    "    #   print(f\"Currently on iteration {i}\")\n",
    "    return en_fr_sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "pAlZ1lwKGkqw"
   },
   "outputs": [],
   "source": [
    "en_fr_sents = process_europarl_corpus(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Cncwu22yKT9n"
   },
   "outputs": [],
   "source": [
    "en_fr_df = pd.DataFrame(en_fr_sents, columns=[\"en\", \"fr\"])\n",
    "# en_fr_df = en_fr_df.loc[:1000000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 320
    },
    "id": "6pyoJiIlOoOS",
    "outputId": "8ebf62b2-585d-4abd-b6e8-3067daf690c2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>en</th>\n",
       "      <th>fr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Resumption of the session</td>\n",
       "      <td>Reprise de la session</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I declare resumed the session of the European ...</td>\n",
       "      <td>Je déclare reprise la session du Parlement eur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Although, as you will have seen, the dreaded '...</td>\n",
       "      <td>Comme vous avez pu le constater, le grand \"bog...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>You have requested a debate on this subject in...</td>\n",
       "      <td>Vous avez souhaité un débat à ce sujet dans le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In the meantime, I should like to observe a mi...</td>\n",
       "      <td>En attendant, je souhaiterais, comme un certai...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  en  \\\n",
       "0                          Resumption of the session   \n",
       "1  I declare resumed the session of the European ...   \n",
       "2  Although, as you will have seen, the dreaded '...   \n",
       "3  You have requested a debate on this subject in...   \n",
       "4  In the meantime, I should like to observe a mi...   \n",
       "\n",
       "                                                  fr  \n",
       "0                              Reprise de la session  \n",
       "1  Je déclare reprise la session du Parlement eur...  \n",
       "2  Comme vous avez pu le constater, le grand \"bog...  \n",
       "3  Vous avez souhaité un débat à ce sujet dans le...  \n",
       "4  En attendant, je souhaiterais, comme un certai...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_fr_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "usxGODfYoTBI"
   },
   "outputs": [],
   "source": [
    "def preprocess(text, nltk_tokenizer):\n",
    "    #cur_sent = \" \".join([\"cls\"] + nltk_tokenizer.tokenize(text.lower()) + [\"sep\"])\n",
    "    cur_sent = \" \".join([\"cls\"] + [x for x in text.split() if x !=\"\"] + [\"sep\"])\n",
    "    return cur_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "Z81hLgmzonKy"
   },
   "outputs": [],
   "source": [
    "nltk_tokenizer = RegexpTokenizer(r\"[\\w\\d'\\s]+\")\n",
    "en_fr_df[\"en\"] = en_fr_df[\"en\"].apply(lambda x: preprocess(x, nltk_tokenizer))\n",
    "en_fr_df[\"fr\"] = en_fr_df[\"fr\"].apply(lambda x: preprocess(x, nltk_tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "Y4o8A-0DnE7n"
   },
   "outputs": [],
   "source": [
    "def generate_mappings(en_fr_df, col_name, start_batch=1, batch_size=10000):\n",
    "  sents = list(set(en_fr_df[col_name].tolist()))\n",
    "  sents.sort()\n",
    "  latest_token_index = 0\n",
    "  sent_to_tokens = {}\n",
    "  token_to_index = {}\n",
    "  token_vector_list = []\n",
    "  seen_tokens = set()\n",
    "  cls_doc = nlp(\"cls\", disable=[\"parser\",\"ner\"])\n",
    "  seen_tokens.add(cls_doc[0].text)\n",
    "  token_to_index[cls_doc[0].text] = latest_token_index\n",
    "  latest_token_index += 1\n",
    "  token_vector_list.append(torch.Tensor(cls_doc[0].vector))\n",
    "  sep_doc = nlp(\"sep\", disable=[\"parser\",\"ner\"])\n",
    "  seen_tokens.add(sep_doc[0].text)\n",
    "  token_to_index[sep_doc[0].text] = latest_token_index\n",
    "  latest_token_index += 1\n",
    "  token_vector_list.append(torch.Tensor(sep_doc[0].vector))\n",
    "  start_time = time.time()\n",
    "  num_sents = len(sents)\n",
    "  num_batches = math.ceil(num_sents/batch_size)\n",
    "  if start_batch > 1:\n",
    "    with open(f\"./data/{col_name}_sent_to_tokens_{start_batch-1}.pkl\", \"rb\") as f:\n",
    "      sent_to_tokens = pickle.load(f)\n",
    "    with open(f\"./data/{col_name}_token_to_index_{start_batch-1}.pkl\", \"rb\") as f:\n",
    "      token_to_index = pickle.load(f)\n",
    "    with open(f\"./data/{col_name}_token_vectors_{start_batch-1}.pkl\", \"rb\") as f:\n",
    "      token_vectors = pickle.load(f)\n",
    "  print(f\"Number of sentences: {num_sents}\")\n",
    "  print(f\"Number of batches: {num_batches}\")\n",
    "  for batch in range(start_batch,num_batches+1):\n",
    "    batch_start_index = (batch-1)*batch_size\n",
    "    docs = nlp.pipe(sents[batch_start_index:min(batch*batch_size, num_sents)], disable=[\"parser\", \"ner\"])\n",
    "    for i,doc in enumerate(docs):\n",
    "      cur_sent_tokens = []\n",
    "      for token in doc:\n",
    "        cur_sent_tokens.append(token.text)\n",
    "        if token.text not in seen_tokens:\n",
    "          seen_tokens.add(token.text)\n",
    "          token_to_index[token.text] = latest_token_index\n",
    "          latest_token_index += 1\n",
    "          token_vector_list.append(torch.Tensor(token.vector))\n",
    "        sent_to_tokens[sents[batch_start_index+i]] = cur_sent_tokens\n",
    "    with open(f\"./data/{col_name}_sent_to_tokens_{batch}.pkl\", \"wb\") as f:\n",
    "      pickle.dump(sent_to_tokens, f)\n",
    "    with open(f\"./data/{col_name}_token_to_index_{batch}.pkl\", \"wb\") as f:\n",
    "      pickle.dump(token_to_index, f)\n",
    "    with open(f\"./data/{col_name}_token_vectors_{batch}.pkl\", \"wb\") as f:\n",
    "      pickle.dump(token_vector_list, f)\n",
    "    end_time = time.time()\n",
    "    total_time = end_time-start_time\n",
    "    print(f\"Total time to finish batch {batch} is: {total_time/60} minutes\")\n",
    "    start_time = time.time()\n",
    "  token_vectors = torch.stack(token_vector_list)\n",
    "  index_to_token = {i:token for token,i in token_to_index.items()}\n",
    "  return sent_to_tokens,token_to_index,index_to_token,token_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_mappings_batch(en_fr_df, col_name, batch=1, batch_size=200000):\n",
    "  sents = list(set(en_fr_df.loc[(batch-1)*batch_size:min(batch*batch_size,len(en_fr_df)),col_name].tolist()))\n",
    "  sents.sort()\n",
    "  latest_token_index = 0\n",
    "  sent_to_tokens = {}\n",
    "  token_to_index = {}\n",
    "  token_vector_list = []\n",
    "  seen_tokens = set()\n",
    "  cls_doc = nlp(\"cls\", disable=[\"parser\",\"ner\"])\n",
    "  seen_tokens.add(cls_doc[0].text)\n",
    "  token_to_index[cls_doc[0].text] = latest_token_index\n",
    "  latest_token_index += 1\n",
    "  token_vector_list.append(torch.Tensor(cls_doc[0].vector))\n",
    "  sep_doc = nlp(\"sep\", disable=[\"parser\",\"ner\"])\n",
    "  seen_tokens.add(sep_doc[0].text)\n",
    "  token_to_index[sep_doc[0].text] = latest_token_index\n",
    "  latest_token_index += 1\n",
    "  token_vector_list.append(torch.Tensor(sep_doc[0].vector))\n",
    "  start_time = time.time()\n",
    "  num_sents = len(sents)\n",
    "  print(f\"Number of sentences: {num_sents}\")\n",
    "  docs = nlp.pipe(sents, disable=[\"parser\", \"ner\"])\n",
    "  for i,doc in enumerate(docs):\n",
    "    cur_sent_tokens = []\n",
    "    for token in doc:\n",
    "      cur_sent_tokens.append(token.text)\n",
    "      if token.text not in seen_tokens:\n",
    "        seen_tokens.add(token.text)\n",
    "        token_to_index[token.text] = latest_token_index\n",
    "        latest_token_index += 1\n",
    "        token_vector_list.append(torch.Tensor(token.vector))\n",
    "      sent_to_tokens[sents[i]] = cur_sent_tokens\n",
    "  token_vectors = torch.stack(token_vector_list)\n",
    "  index_to_token = {i:token for token,i in token_to_index.items()}\n",
    "  end_time = time.time()\n",
    "  total_time = end_time-start_time\n",
    "  print(f\"Total time to finish batch {batch} is: {total_time/60} minutes\")\n",
    "  return sent_to_tokens,token_to_index,index_to_token,token_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0laeaR5JsRTY",
    "outputId": "f2132ceb-3468-4607-f6e7-d46865ff2507"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of batches: 10\n",
      "Number of sentences: 196331\n",
      "Total time to finish batch 1 is: 5.084158941109975 minutes\n",
      "Number of sentences: 196239\n",
      "Total time to finish batch 1 is: 4.752089854081472 minutes\n",
      "Number of sentences: 196412\n",
      "Total time to finish batch 2 is: 5.102656066417694 minutes\n",
      "Number of sentences: 196470\n",
      "Total time to finish batch 2 is: 4.877003788948059 minutes\n",
      "Number of sentences: 197046\n",
      "Total time to finish batch 3 is: 5.045820907751719 minutes\n",
      "Number of sentences: 196952\n",
      "Total time to finish batch 3 is: 5.081850055853526 minutes\n",
      "Number of sentences: 197720\n",
      "Total time to finish batch 4 is: 5.214004902044932 minutes\n",
      "Number of sentences: 197635\n",
      "Total time to finish batch 4 is: 5.084834583600363 minutes\n",
      "Number of sentences: 194982\n",
      "Total time to finish batch 5 is: 5.125489791234334 minutes\n",
      "Number of sentences: 194607\n",
      "Total time to finish batch 5 is: 4.951126698652903 minutes\n",
      "Number of sentences: 194480\n",
      "Total time to finish batch 6 is: 4.9694163997968035 minutes\n",
      "Number of sentences: 194162\n",
      "Total time to finish batch 6 is: 4.359127120176951 minutes\n",
      "Number of sentences: 194755\n",
      "Total time to finish batch 7 is: 4.187038330237071 minutes\n",
      "Number of sentences: 194522\n",
      "Total time to finish batch 7 is: 3.8566771864891054 minutes\n",
      "Number of sentences: 193080\n",
      "Total time to finish batch 8 is: 4.03753274679184 minutes\n",
      "Number of sentences: 192869\n",
      "Total time to finish batch 8 is: 4.013493637243907 minutes\n",
      "Number of sentences: 196779\n",
      "Total time to finish batch 9 is: 4.365143855412801 minutes\n",
      "Number of sentences: 196636\n",
      "Total time to finish batch 9 is: 3.9358021020889282 minutes\n",
      "Number of sentences: 196305\n",
      "Total time to finish batch 10 is: 4.129589287439982 minutes\n",
      "Number of sentences: 196298\n",
      "Total time to finish batch 10 is: 3.9842515031496686 minutes\n"
     ]
    }
   ],
   "source": [
    "batch_size = 200000\n",
    "num_batches = math.ceil(len(en_fr_df)//batch_size)\n",
    "print(f\"Number of batches: {num_batches}\")\n",
    "for batch in range(1,num_batches+1):\n",
    "  fr_sent_to_tokens,fr_token_to_index,fr_index_to_token,fr_token_vectors = generate_mappings_batch(en_fr_df, \"fr\", batch=batch, batch_size=batch_size)\n",
    "  en_sent_to_tokens,en_token_to_index,en_index_to_token,en_token_vectors = generate_mappings_batch(en_fr_df, \"en\", batch=batch, batch_size=batch_size)\n",
    "  with open(f\"./data/fr_sent_to_tokens_{batch}.pkl\", \"wb\") as f:\n",
    "    pickle.dump(fr_sent_to_tokens, f)\n",
    "  with open(f\"./data/fr_token_to_index.pkl_{batch}\", \"wb\") as f:\n",
    "    pickle.dump(fr_token_to_index, f)\n",
    "  with open(f\"./data/fr_index_to_token.pkl_{batch}\", \"wb\") as f:\n",
    "    pickle.dump(fr_index_to_token, f)\n",
    "  with open(f\"./data/fr_token_vectors.pkl_{batch}\", \"wb\") as f:\n",
    "    pickle.dump(fr_token_vectors, f)\n",
    "  with open(f\"./data/en_sent_to_tokens.pkl_{batch}\", \"wb\") as f:\n",
    "    pickle.dump(en_sent_to_tokens, f)\n",
    "  with open(f\"./data/en_token_to_index.pkl_{batch}\", \"wb\") as f:\n",
    "    pickle.dump(en_token_to_index, f)\n",
    "  with open(f\"./data/en_index_to_token.pkl_{batch}\", \"wb\") as f:\n",
    "    pickle.dump(en_index_to_token, f)\n",
    "  with open(f\"./data/en_token_vectors.pkl_{batch}\", \"wb\") as f:\n",
    "    pickle.dump(en_token_vectors, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LnJyvALyOqPn",
    "outputId": "0894b5a6-897a-421b-f43a-a8bc51b061a7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([16478, 300]), 16478, 9903, torch.Size([11651, 300]), 11651, 9902)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fr_token_vectors.size(),len(fr_token_to_index),len(fr_sent_to_tokens),en_token_vectors.size(),len(en_token_to_index),len(en_sent_to_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78924\n",
      "79856\n"
     ]
    }
   ],
   "source": [
    "# code to check if the batched data has been created accurately\n",
    "col_names = [\"en\", \"fr\"]\n",
    "final_batch = 10\n",
    "for col_name in col_names:\n",
    "  with open(f\"./data/{col_name}_sent_to_tokens_{final_batch}.pkl\", \"rb\") as f:\n",
    "    sent_to_tokens = pickle.load(f)\n",
    "  print(len(sent_to_tokens.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_fr_df.to_csv(\"./data/en_fr_df.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Below is the main code which needs to be executed to train the encoder decoder architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_fr_df = pd.read_csv(\"./data/en_fr_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "5Pg0PLaxQ4YD"
   },
   "outputs": [],
   "source": [
    "class MTDataset(Dataset):\n",
    "  def __init__(self,df,max_len,batch):\n",
    "    self.df = df\n",
    "    self.max_len = max_len\n",
    "    with open(f\"./data/fr_sent_to_tokens_{batch}.pkl\", \"rb\") as f:\n",
    "      self.fr_sent_to_tokens = pickle.load(f)\n",
    "    with open(f\"./data/fr_token_to_index.pkl_{batch}\", \"rb\") as f:\n",
    "      self.fr_token_to_index = pickle.load(f)\n",
    "    with open(f\"./data/fr_index_to_token.pkl_{batch}\", \"rb\") as f:\n",
    "      self.fr_index_to_token = pickle.load(f)\n",
    "    with open(f\"./data/fr_token_vectors.pkl_{batch}\", \"rb\") as f:\n",
    "      self.fr_token_vectors = pickle.load(f)\n",
    "    with open(f\"./data/en_sent_to_tokens.pkl_{batch}\", \"rb\") as f:\n",
    "      self.en_sent_to_tokens = pickle.load(f)\n",
    "    with open(f\"./data/en_token_to_index.pkl_{batch}\", \"rb\") as f:\n",
    "      self.en_token_to_index = pickle.load(f)\n",
    "    with open(f\"./data/en_index_to_token.pkl_{batch}\", \"rb\") as f:\n",
    "      self.en_index_to_token = pickle.load(f)\n",
    "    with open(f\"./data/en_token_vectors.pkl_{batch}\", \"rb\") as f:\n",
    "      self.en_token_vectors = pickle.load(f)\n",
    "  def __len__(self):\n",
    "    return len(self.df)\n",
    "  def __getitem__(self, idx):\n",
    "    cur_en_sent = self.df.loc[idx,\"en\"]\n",
    "    cur_fr_sent = self.df.loc[idx,\"fr\"]\n",
    "    cur_en_tokens = self.en_sent_to_tokens[cur_en_sent]\n",
    "    cur_fr_tokens = self.fr_sent_to_tokens[cur_fr_sent]\n",
    "    if (len(cur_en_tokens))>self.max_len or (len(cur_fr_tokens))>self.max_len:\n",
    "      raise Exception(\"The input or target sentence is more than max len tokens\")\n",
    "    inputs = torch.stack([torch.Tensor(self.en_token_vectors[self.en_token_to_index[token]]) for token in cur_en_tokens])\n",
    "    targets = torch.stack([torch.Tensor(self.fr_token_vectors[self.fr_token_to_index[token]]) for token in cur_fr_tokens[:-1]])\n",
    "    labels = torch.LongTensor([self.fr_token_to_index[token] for token in cur_fr_tokens[1:]])\n",
    "    return {\n",
    "        \"inputs\":inputs,\n",
    "        \"targets\": targets,\n",
    "        \"input_seq_len\": torch.LongTensor([len(inputs)]),\n",
    "        \"target_seq_len\": torch.LongTensor([len(targets)]),\n",
    "        \"labels\": labels\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "PDPJQ7fX_MhV"
   },
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "  ignore_index = -1\n",
    "  inputs = nn.utils.rnn.pad_sequence([batch[i][\"inputs\"] for i in range(len(batch))], batch_first=True)\n",
    "  input_seq_lens = torch.stack([batch[i][\"input_seq_len\"] for i in range(len(batch))]).squeeze()\n",
    "  targets = nn.utils.rnn.pad_sequence([batch[i][\"targets\"] for i in range(len(batch))], batch_first=True)\n",
    "  target_seq_lens = torch.stack([batch[i][\"target_seq_len\"] for i in range(len(batch))]).squeeze()\n",
    "  labels = nn.utils.rnn.pad_sequence([batch[i][\"labels\"] for i in range(len(batch))], batch_first=True, padding_value=ignore_index)\n",
    "  return inputs,targets,input_seq_lens,target_seq_lens,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "hHRKbJ6YmjBM"
   },
   "outputs": [],
   "source": [
    "def auto_reg_collate_fn(batch):\n",
    "  max_len=512\n",
    "  ignore_index = -1\n",
    "  inputs = nn.utils.rnn.pad_sequence([batch[i][\"inputs\"] for i in range(len(batch))], batch_first=True)\n",
    "  input_seq_lens = torch.stack([batch[i][\"input_seq_len\"] for i in range(len(batch))]).squeeze()\n",
    "  targets = torch.stack([batch[i][\"targets\"][0] for i in range(len(batch))])\n",
    "  labels = nn.utils.rnn.pad_sequence([batch[i][\"labels\"] for i in range(len(batch))], batch_first=True, padding_value=ignore_index)\n",
    "  ignore_index_vals = torch.full((1,max_len-1-labels.size()[-1]), ignore_index).expand(len(batch), -1)\n",
    "  labels = torch.cat([labels, ignore_index_vals], dim=-1)\n",
    "  return inputs,targets,input_seq_lens,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "HI-zzqU1Si-y"
   },
   "outputs": [],
   "source": [
    "max_len = 512\n",
    "dataset_batch_size = 200000\n",
    "batch_size = 16\n",
    "train_datasets = []\n",
    "train_dataloaders = []\n",
    "valid_dataset = None\n",
    "valid_dataloader = None\n",
    "test_dataset = None\n",
    "test_dataloader = None\n",
    "num_train_batches = num_batches-2\n",
    "for batch in range(1,num_batches+1):\n",
    "  cur_ds = MTDataset(en_fr_df.loc[(batch-1)*dataset_batch_size:min(batch*dataset_batch_size,len(en_fr_df))].reset_index(drop=True),max_len,batch)\n",
    "  if batch <= num_train_batches:\n",
    "    train_datasets.append(cur_ds)\n",
    "    train_dataloaders.append(DataLoader(cur_ds, batch_size=batch_size, collate_fn=collate_fn))\n",
    "  elif batch == num_batches-1:\n",
    "    valid_dataset = cur_ds\n",
    "    valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size, collate_fn=auto_reg_collate_fn)\n",
    "  else:\n",
    "    test_dataset = cur_ds\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=batch_size, collate_fn=auto_reg_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = set()\n",
    "for batch in range(1,num_batches+1):\n",
    "  with open(f\"./data/fr_token_to_index.pkl_{batch}\", \"rb\") as f:\n",
    "    cur_fr_token_to_index = pickle.load(f)\n",
    "  vocab = vocab.union(set(cur_fr_token_to_index.keys()))\n",
    "vocab_size = len(vocab)\n",
    "print(f\"Vocab size is: {vocab_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NdHkNubt_ccA",
    "outputId": "0b5f9a7e-90c1-4000-b2d2-039cdb6baea1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 82, 300]) torch.Size([64, 300]) torch.Size([64]) torch.Size([64, 511])\n"
     ]
    }
   ],
   "source": [
    "cur_batch = next(iter(valid_dataloader))\n",
    "print(cur_batch[0].size(),cur_batch[1].size(),cur_batch[2].size(),cur_batch[3].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2hY-_6jZSn1x",
    "outputId": "01ff8c30-c974-49b6-b882-44c5aadb3ed8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'inputs': tensor([[ 0.1240, -0.0542,  0.1174,  ...,  0.0663, -0.1964,  0.1107],\n",
       "         [ 2.3200, -1.9738,  2.2365,  ...,  1.6454, -2.3114,  0.0521],\n",
       "         [-3.3899, -4.7034, -0.5610,  ...,  0.7367, -0.6270,  0.0711],\n",
       "         ...,\n",
       "         [ 2.5807, -2.2430, -4.2179,  ..., -1.4946, -8.1377, -0.0715],\n",
       "         [-0.0765, -4.6896, -4.0431,  ...,  1.3040, -0.5270, -1.3622],\n",
       "         [-0.1954, -1.7745, -2.6836,  ..., -2.3685,  0.7443, -2.5710]]),\n",
       " 'targets': tensor([[ 0.1240, -0.0542,  0.1174,  ...,  0.0663, -0.1964,  0.1107],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [-0.0516,  0.3672,  0.5925,  ...,  0.3374, -1.2198, -2.0908],\n",
       "         ...,\n",
       "         [-0.8452, -2.6627, -0.4257,  ...,  1.1522, -0.6051, -0.0155],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [-0.0765, -4.6896, -4.0431,  ...,  1.3040, -0.5270, -1.3622]]),\n",
       " 'input_seq_len': tensor([28]),\n",
       " 'target_seq_len': tensor([22]),\n",
       " 'labels': tensor([11677,    69,    45,    47,   921,   634,  3326,    28,  2118,    47,\n",
       "            29,   612,    16,   699,    16,  1342,  2428,    53,  1503, 11678,\n",
       "            42,     1])}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_datasets[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "67avlJ9dZWn6"
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "  def __init__(self, emb_dim, enc_hidden_dim, train_emb=False):\n",
    "    super().__init__()\n",
    "    self.GRU = nn.GRU(emb_dim, enc_hidden_dim)\n",
    "    self.layernorm_layer = nn.LayerNorm(enc_hidden_dim)\n",
    "  def forward(self, inputs, input_seq_lens):\n",
    "    inputs = nn.utils.rnn.pack_padded_sequence(inputs, input_seq_lens.cpu(), batch_first=True, enforce_sorted=False)\n",
    "    outputs, hidden = self.GRU(inputs)\n",
    "    hidden = self.layernorm_layer(hidden)\n",
    "    return outputs, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "uRJxmPzqfRhp"
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "  def __init__(self, emb_dim, enc_hidden_dim, dec_hidden_dim, vocab_size, train_emb=False):\n",
    "    super().__init__()\n",
    "    self.GRU = nn.GRU(emb_dim+enc_hidden_dim, dec_hidden_dim)\n",
    "    self.layernorm_layer = nn.LayerNorm(dec_hidden_dim)\n",
    "    self.dense_layer = nn.Linear(dec_hidden_dim, vocab_size)\n",
    "    self.softmax_layer = nn.Softmax(dim=-1)\n",
    "  def forward(self, context_vector, init_hidden_state, targets, target_seq_lens):\n",
    "    targets_with_context = torch.cat([targets, context_vector.unsqueeze(dim=1).expand(-1, targets.size()[1], -1)], dim=-1)\n",
    "    targets_with_context = nn.utils.rnn.pack_padded_sequence(targets_with_context, target_seq_lens.cpu(), batch_first=True, enforce_sorted=False)\n",
    "    outputs, hidden = self.GRU(targets_with_context, init_hidden_state)\n",
    "    outputs, seq_lens = nn.utils.rnn.pad_packed_sequence(outputs, batch_first=True)\n",
    "    outputs = self.layernorm_layer(outputs)\n",
    "    x = self.dense_layer(outputs)\n",
    "    x = self.softmax_layer(x)\n",
    "    return hidden,x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yveiZua88LqS",
    "outputId": "240306ce-82f9-453b-c486-451a29d0a08d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 115, 300]) torch.Size([64, 127, 300]) torch.Size([64]) torch.Size([64]) torch.Size([64, 127])\n",
      "torch.Size([64, 128]) torch.Size([64, 127, 300])\n",
      "torch.Size([1, 64, 128]) torch.Size([64, 16478, 127])\n"
     ]
    }
   ],
   "source": [
    "emb_dim = 300\n",
    "enc_hidden_dim = 128\n",
    "dec_hidden_dim = 128\n",
    "enc = Encoder(emb_dim, enc_hidden_dim)\n",
    "dec = Decoder(emb_dim, enc_hidden_dim, dec_hidden_dim, vocab_size)\n",
    "inputs,targets,input_seq_lens,target_seq_lens,labels = next(iter(train_dataloaders[0]))\n",
    "print(inputs.size(),targets.size(),input_seq_lens.size(),target_seq_lens.size(),labels.size())\n",
    "_, context = enc(inputs, input_seq_lens)\n",
    "print(context.squeeze().size(), targets.size())\n",
    "hidden_state,decoder_output = dec(context.squeeze(), context, targets, target_seq_lens)\n",
    "decoder_output = decoder_output.permute(0,-1,1)\n",
    "print(hidden_state.size(), decoder_output.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EvS0XWEiWKRO",
    "outputId": "c8a4dd14-5ac2-41e4-a147-c39f304406b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Module.parameters of Encoder(\n",
      "  (GRU): GRU(300, 128)\n",
      "  (layernorm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      ")>\n",
      "<bound method Module.parameters of Decoder(\n",
      "  (GRU): GRU(428, 128)\n",
      "  (layernorm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "  (dense_layer): Linear(in_features=128, out_features=16478, bias=True)\n",
      "  (softmax_layer): Softmax(dim=-1)\n",
      ")>\n"
     ]
    }
   ],
   "source": [
    "emb_dim = 300\n",
    "enc_hidden_dim = 128\n",
    "dec_hidden_dim = 128\n",
    "enc = Encoder(emb_dim, enc_hidden_dim, en_token_vectors)\n",
    "dec = Decoder(emb_dim, enc_hidden_dim, dec_hidden_dim, fr_token_vectors)\n",
    "enc.to(device)\n",
    "dec.to(device)\n",
    "loss_fn = nn.CrossEntropyLoss(ignore_index=-1)\n",
    "encoder_optimizer = optim.Adam(enc.parameters(), lr=1e-3)\n",
    "decoder_optimizer = optim.Adam(dec.parameters(), lr=1e-3)\n",
    "print(enc.parameters)\n",
    "print(dec.parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DoHr7blTUb7A",
    "outputId": "3aa97ff8-1d82-46f2-f1a1-e6b32b92f4bf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/125 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of batches: 125.0\n",
      "EPOCH 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▋                                                                                  | 1/125 [00:11<23:19, 11.29s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_8402/1095501612.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mhidden_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdecoder_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_seq_lens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mdecoder_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mencoder_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/encoder_decoder_base_env/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/encoder_decoder_base_env/lib/python3.7/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1164\u001b[0m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[1;32m   1165\u001b[0m                                \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1166\u001b[0;31m                                label_smoothing=self.label_smoothing)\n\u001b[0m\u001b[1;32m   1167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/encoder_decoder_base_env/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3012\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3013\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3014\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_smoothing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3016\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if os.path.exists(\"./log.txt\"):\n",
    "    os.remove(\"./log.txt\")\n",
    "teacher_forcing = True\n",
    "epochs = 10\n",
    "print(f\"number of batches: {len(train_ds[0])/batch_size}\")\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "min_valid_epoch_loss = float(\"inf\")\n",
    "total_trainloaders_len = sum([len(x) for x in train_dataloaders])\n",
    "for epoch_num in range(epochs):\n",
    "  print(f\"EPOCH {epoch_num}\")\n",
    "  running_loss = 0\n",
    "  epoch_start_time = time.time()\n",
    "  enc.train()\n",
    "  dec.train()\n",
    "  for train_dataloader in train_dataloaders:\n",
    "    batch_start_time = time.time()\n",
    "    cur_batch_start_time = time.time()\n",
    "    for batch_num,batch in enumerate(tqdm(train_dataloader)):\n",
    "      inputs,targets,input_seq_lens,target_seq_lens,labels = next(iter(train_dataloader))\n",
    "      inputs = inputs.to(device)\n",
    "      targets = targets.to(device)\n",
    "      input_seq_lens = input_seq_lens.to(device)\n",
    "      target_seq_lens = target_seq_lens.to(device)\n",
    "      labels = labels.to(device)\n",
    "      _, context = enc(inputs, input_seq_lens)\n",
    "      hidden_state,decoder_output = dec(context.squeeze(dim=0), context, targets, target_seq_lens)\n",
    "      decoder_output = decoder_output.permute(0,-1,1)\n",
    "      loss = loss_fn(decoder_output, labels)\n",
    "      loss.backward()\n",
    "      encoder_optimizer.step()\n",
    "      decoder_optimizer.step()\n",
    "      encoder_optimizer.zero_grad()\n",
    "      decoder_optimizer.zero_grad()\n",
    "      running_loss += loss\n",
    "      if batch_num%500==0:\n",
    "          batch_end_time = time.time()\n",
    "          batch_total_time = batch_end_time-batch_start_time\n",
    "          # print(f\"BATCH_END,epoch:{epoch_num},batch:{batch_num},loss:{loss},time:{batch_total_time/60}\")\n",
    "          # print(decoder_output.size(),labels.size())\n",
    "          with open(\"./log.txt\", \"a+\") as f:\n",
    "            f.write(f\"BATCH_END,epoch:{epoch_num},batch:{batch_num},loss:{loss},time:{batch_total_time/60}\\n\")\n",
    "          batch_start_time = time.time()\n",
    "      #print(f\"Finished batch {batch_num} in time {(time.time()-cur_batch_start_time)/60} minutes\")\n",
    "      #cur_batch_start_time = time.time()\n",
    "  train_epoch_loss = running_loss/total_trainloaders_len\n",
    "  train_losses.append(train_epoch_loss)\n",
    "  epoch_end_time = time.time()\n",
    "  epoch_total_time = epoch_end_time-epoch_start_time\n",
    "  print(f\"EPOCH_END,epoch:{epoch_num},loss:{train_epoch_loss},time:{epoch_total_time/60}\")\n",
    "  with open(\"./log.txt\", \"a+\") as f:\n",
    "    f.write(f\"EPOCH_END,epoch:{epoch_num},loss:{train_epoch_loss},time:{epoch_total_time/60}\\n\")\n",
    "  with torch.no_grad():\n",
    "    enc.eval()\n",
    "    dec.eval()\n",
    "    print(\"Running Validation...\")\n",
    "    running_loss = 0\n",
    "    epoch_start_time = time.time()\n",
    "    for batch_num,batch in enumerate(tqdm(valid_dataloader)):\n",
    "      inputs,targets,input_seq_lens,labels = batch\n",
    "      inputs = inputs.to(device)\n",
    "      targets = targets.to(device)\n",
    "      input_seq_lens = input_seq_lens.to(device)\n",
    "      labels = labels.to(device)\n",
    "      _, context = enc(inputs, input_seq_lens)\n",
    "      decoder_final_outputs = []\n",
    "      for decoder_start_index in range(len(targets)):\n",
    "        num_decoder_output_tokens = 1\n",
    "        cur_predicted_token = None\n",
    "        cur_context_vector = context[:,decoder_start_index,:].unsqueeze(dim=1)\n",
    "        decoder_start_vector = targets[decoder_start_index].unsqueeze(0).unsqueeze(0)\n",
    "        cur_input_vector = decoder_start_vector\n",
    "        prev_hidden_state = cur_context_vector\n",
    "        decoder_sequence_outputs = []\n",
    "        while cur_predicted_token!=\"sep\" and num_decoder_output_tokens<max_len:\n",
    "          hidden_state,decoder_output = dec(cur_context_vector.squeeze(dim=0), prev_hidden_state, cur_input_vector, torch.LongTensor([1]))\n",
    "          cur_predicted_token_index = int(torch.argmax(decoder_output[0,0,:]))\n",
    "          cur_predicted_token = fr_index_to_token[cur_predicted_token_index]\n",
    "          prev_hidden_state = hidden_state\n",
    "          cur_input_vector = fr_token_vectors[cur_predicted_token_index].unsqueeze(0).unsqueeze(0)\n",
    "          cur_input_vector.to(device)\n",
    "          num_decoder_output_tokens += 1\n",
    "          decoder_sequence_outputs.append(decoder_output)\n",
    "        decoder_sequence_output = torch.cat(decoder_sequence_outputs, dim=1)\n",
    "        pad_matrix = torch.full((1,max_len-num_decoder_output_tokens,decoder_sequence_output.size()[-1]), 0)\n",
    "        decoder_sequence_output = torch.cat([decoder_sequence_output,pad_matrix], dim=1)\n",
    "        decoder_final_outputs.append(decoder_sequence_output)\n",
    "      decoder_final_output = torch.cat(decoder_final_outputs, dim=0)\n",
    "      decoder_final_output = decoder_final_output.permute(0,-1,1)\n",
    "      running_loss += loss_fn(decoder_final_output, labels)\n",
    "    valid_epoch_loss = running_loss/len(valid_dataloader)\n",
    "    valid_losses.append(valid_epoch_loss)\n",
    "    if valid_epoch_loss < min_valid_epoch_loss:\n",
    "      min_valid_epoch_loss = valid_epoch_loss\n",
    "      print(f\"Saving model after training epoch {epoch_num} with loss {min_valid_epoch_loss}...\")\n",
    "      with open(\"./log.txt\", \"a+\") as f:\n",
    "        f.write(f\"Saving model after training epoch {epoch_num} with loss {min_valid_epoch_loss}...\\n\")\n",
    "      torch.save(enc.state_dict(), f\"./best_enc_{epoch_num}_{min_valid_epoch_loss}.bin\")\n",
    "      torch.save(dec.state_dict(), f\"./best_dec_{epoch_num}_{min_valid_epoch_loss}.bin\")\n",
    "    epoch_end_time = time.time()\n",
    "    epoch_total_time = epoch_end_time-epoch_start_time\n",
    "    print(f\"VALID_EPOCH_END,loss:{valid_epoch_loss},time:{epoch_total_time/60}\")\n",
    "    with open(\"./log.txt\", \"a+\") as f:\n",
    "      f.write(f\"VALID_EPOCH_END,loss:{valid_epoch_loss},time:{epoch_total_time/60}\\n\")\n",
    "with open(\"./data/train_losses.pkl\", \"wb\") as f:\n",
    "  pickle.dump(train_losses, f)\n",
    "with open(\"./data/valid_losses.pkl\", \"wb\") as f:\n",
    "  pickle.dump(valid_losses, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Below is additional test code which does not need to be executed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t_7Wu8AaqNl_",
    "outputId": "89276766-ad39-49ac-a419-05cb8891a95f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:21<00:21, 21.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 511, 4648]) torch.Size([64, 511])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:34<00:00, 17.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([36, 511, 4648]) torch.Size([36, 511])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(len(valid_ds), len(valid_dataloader))\n",
    "with torch.no_grad():\n",
    "    enc.eval()\n",
    "    dec.eval()\n",
    "    for batch_num,batch in enumerate(tqdm(valid_dataloader)):\n",
    "      inputs,targets,input_seq_lens,labels = batch\n",
    "      inputs = inputs.to(device)\n",
    "      targets = targets.to(device)\n",
    "      input_seq_lens = input_seq_lens.to(device)\n",
    "      labels = labels.to(device)\n",
    "      _, context = enc(inputs, input_seq_lens)\n",
    "      decoder_final_outputs = []\n",
    "      for decoder_start_index in range(len(targets)):\n",
    "        num_decoder_output_tokens = 1\n",
    "        cur_predicted_token = None\n",
    "        cur_context_vector = context[:,decoder_start_index,:].unsqueeze(dim=1)\n",
    "        decoder_start_vector = targets[decoder_start_index].unsqueeze(0).unsqueeze(0)\n",
    "        cur_input_vector = decoder_start_vector\n",
    "        prev_hidden_state = cur_context_vector\n",
    "        decoder_sequence_outputs = []\n",
    "        while cur_predicted_token!=\"sep\" and num_decoder_output_tokens<max_len:\n",
    "          hidden_state,decoder_output = dec(cur_context_vector.squeeze(dim=0), prev_hidden_state, cur_input_vector, torch.LongTensor([1]))\n",
    "          cur_predicted_token_index = int(torch.argmax(decoder_output[0,0,:]))\n",
    "          cur_predicted_token = fr_index_to_token[cur_predicted_token_index]\n",
    "          prev_hidden_state = hidden_state\n",
    "          cur_input_vector = fr_token_vectors[cur_predicted_token_index].unsqueeze(0).unsqueeze(0)\n",
    "          cur_input_vector.to(device)\n",
    "          num_decoder_output_tokens += 1\n",
    "          decoder_sequence_outputs.append(decoder_output)\n",
    "        decoder_sequence_output = torch.cat(decoder_sequence_outputs, dim=1)\n",
    "        pad_matrix = torch.full((1,max_len-num_decoder_output_tokens,decoder_sequence_output.size()[-1]), 0)\n",
    "        decoder_sequence_output = torch.cat([decoder_sequence_output,pad_matrix], dim=1)\n",
    "        decoder_final_outputs.append(decoder_sequence_output)\n",
    "      decoder_final_output = torch.cat(decoder_final_outputs, dim=0)\n",
    "      print(decoder_final_output.size(), labels.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 450
    },
    "id": "xzzM_wZxHbpt",
    "outputId": "6b4bfc38-4e4d-4645-fef7-4776eee1ea11"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of batches: 1875.0\n",
      "End of batch 0, current loss is 11.211583137512207, total time taken: 0.00957711140314738\n",
      "End of batch 100, current loss is 11.079082489013672, total time taken: 0.7673563559850057\n",
      "End of batch 200, current loss is 11.04337215423584, total time taken: 1.5181862950325011\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-119-e0bb839e4e4a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m#print(inputs, target_ids, labels)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;31m#print(\"===========\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0mhidden_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdecoder_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;31m#print(\"=======================\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-104-80c6920f8793>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# x = self.embedding_layer(inputs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGRU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayernorm_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    949\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m             result = _VF.gru(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0;32m--> 951\u001b[0;31m                              self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[1;32m    952\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    953\u001b[0m             result = _VF.gru(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "teacher_forcing = True\n",
    "epochs = 10\n",
    "batch_size = 128\n",
    "print(f\"number of batches: {len(train_ds)/batch_size}\")\n",
    "for epoch in range(epochs):\n",
    "  encoder_optimizer.zero_grad()\n",
    "  decoder_optimizer.zero_grad()\n",
    "  running_loss = 0\n",
    "  loss = 0\n",
    "  batch_num = 0\n",
    "  epoch_start_time = time.time()\n",
    "  batch_start_time = time.time()\n",
    "  cur_batch_start_time = time.time()\n",
    "  for i in range(len(train_ds)):\n",
    "    inputs = train_ds[i]['inputs']\n",
    "    targets = train_ds[i]['targets']\n",
    "    labels = train_ds[i]['labels']\n",
    "    inputs = inputs.to(device)\n",
    "    targets = targets.to(device)\n",
    "    labels = labels.to(device)\n",
    "    #print(inputs, target_ids, labels)\n",
    "    #print(\"===========\")\n",
    "    _, context = enc(inputs)\n",
    "    hidden_state,decoder_output = dec(context, context, targets)\n",
    "    #print(\"=======================\")\n",
    "    #print(decoder_outputs.size(), labels.size())\n",
    "    #print(target_ids, torch.argmax(decoder_outputs, dim=-1),  labels)\n",
    "    #print(\"=======================\")\n",
    "    #print(decoder_outputs.size(), labels.size())\n",
    "    # if i % 1000==0:\n",
    "    #   print(torch.gather(decoder_outputs, -1, labels.unsqueeze(dim=-1)))\n",
    "    loss += loss_fn(decoder_output, labels)\n",
    "    #loss.backward()\n",
    "    # print(\"========BEFORE STEP\")\n",
    "    # print(enc.GRU.weight_ih_l0[280,50], enc.GRU.weight_ih_l0.grad[280,50])\n",
    "    # print(dec.GRU.weight_ih_l0[280,50], dec.GRU.weight_ih_l0.grad[280,50])\n",
    "    # if i%1000==0:\n",
    "    #   print(hidden_state)\n",
    "    # max_grad = torch.max(dec.dense_layer.weight.grad)\n",
    "    # max_grad_pos = (dec.dense_layer.weight.grad==max_grad).nonzero()\n",
    "    # max_grad_x = int(max_grad_pos[0][0])\n",
    "    # max_grad_y = int(max_grad_pos[0][1])\n",
    "    # print(dec.dense_layer.weight[max_grad_x,max_grad_y],dec.dense_layer.weight.grad[max_grad_x,max_grad_y], max_grad, max_grad_pos[0])\n",
    "    # encoder_optimizer.step()\n",
    "    # decoder_optimizer.step()\n",
    "    # print(\"========AFTER STEP\")\n",
    "    # print(enc.GRU.weight_ih_l0[280,50], enc.GRU.weight_ih_l0.grad[280,50])\n",
    "    # print(dec.GRU.weight_ih_l0[280,50], dec.GRU.weight_ih_l0.grad[280,50])\n",
    "    # print(dec.dense_layer.weight[max_grad_x,max_grad_y],dec.dense_layer.weight.grad[max_grad_x,max_grad_y], max_grad, max_grad_pos[0])\n",
    "    if (i+1) % batch_size == 0:\n",
    "      running_loss += loss\n",
    "      loss.backward()\n",
    "      # print(\"========BEFORE STEP\")\n",
    "      # print(enc.GRU.weight_ih_l0[280,50], enc.GRU.weight_ih_l0.grad[280,50])\n",
    "      # print(dec.GRU.weight_ih_l0[280,50], dec.GRU.weight_ih_l0.grad[280,50])\n",
    "      encoder_optimizer.step()\n",
    "      decoder_optimizer.step()\n",
    "      # print(\"========AFTER STEP\")\n",
    "      # print(enc.GRU.weight_ih_l0[280,50], enc.GRU.weight_ih_l0.grad[280,50])\n",
    "      # print(dec.GRU.weight_ih_l0[280,50], dec.GRU.weight_ih_l0.grad[280,50])\n",
    "      encoder_optimizer.zero_grad()\n",
    "      decoder_optimizer.zero_grad()\n",
    "      if batch_num%100==0:\n",
    "        batch_end_time = time.time()\n",
    "        batch_total_time = batch_end_time-batch_start_time\n",
    "        print(f\"End of batch {batch_num}, current loss is {loss/batch_size}, total time taken: {batch_total_time/60}\")\n",
    "      # print(f\"Finished batch {batch_num} in time {(time.time()-cur_batch_start_time)/60} minutes\")\n",
    "      cur_batch_start_time = time.time()\n",
    "      loss = 0\n",
    "      batch_num +=1\n",
    "  running_loss += loss\n",
    "  loss.backward()\n",
    "  encoder_optimizer.step()\n",
    "  decoder_optimizer.step()\n",
    "  epoch_end_time = time.time()\n",
    "  epoch_total_time = epoch_end_time-epoch_start_time\n",
    "  print(f\"End of epoch {epoch}, current loss is {running_loss/len(train_ds)}, total time taken: {epoch_total_time/60}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 520
    },
    "id": "xCOr6FOfciSv",
    "outputId": "394bc5c3-d6aa-4794-df4b-0f666844add6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of batches: 937.5\n",
      "End of batch 0, current loss is 11.209644317626953, total time taken: 0.16027901967366537\n",
      "Finished batch 0 in time 0.1602869470914205 minutes\n",
      "Finished batch 1 in time 0.1357125719388326 minutes\n",
      "Finished batch 2 in time 0.1436716914176941 minutes\n",
      "Finished batch 3 in time 0.14378207127253215 minutes\n",
      "Finished batch 4 in time 0.15283559958140056 minutes\n",
      "Finished batch 5 in time 0.14501917362213135 minutes\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-81-09ebfcd3aa50>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m       \u001b[0mcur_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m       \u001b[0mhidden_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdecoder_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprev_hidden_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m       \u001b[0mprev_hidden_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m       \u001b[0mprev_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-78-1e1c2a2787d2>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, context_vector, init_hidden_state, targets)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mtargets_with_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext_vector\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGRU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargets_with_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_hidden_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayernorm_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    949\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m             result = _VF.gru(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0;32m--> 951\u001b[0;31m                              self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[1;32m    952\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    953\u001b[0m             result = _VF.gru(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "teacher_forcing = True\n",
    "epochs = 10\n",
    "batch_size = 256\n",
    "print(f\"number of batches: {len(train_ds)/batch_size}\")\n",
    "for epoch in range(epochs):\n",
    "  encoder_optimizer.zero_grad()\n",
    "  decoder_optimizer.zero_grad()\n",
    "  running_loss = 0\n",
    "  loss = 0\n",
    "  batch_num = 0\n",
    "  epoch_start_time = time.time()\n",
    "  batch_start_time = time.time()\n",
    "  cur_batch_start_time = time.time()\n",
    "  for i in range(len(train_ds)):\n",
    "    inputs = train_ds[i]['input_ids']\n",
    "    target_ids = train_ds[i]['target_ids']\n",
    "    labels = train_ds[i]['labels']\n",
    "    inputs = inputs.to(device)\n",
    "    target_ids = target_ids.to(device)\n",
    "    labels = labels.to(device)\n",
    "    #print(inputs, target_ids, labels)\n",
    "    #print(\"===========\")\n",
    "    _, context = enc(inputs)\n",
    "    prev_hidden_state = context\n",
    "    prev_label = None\n",
    "    decoder_outputs = []\n",
    "    for j in range(len(target_ids)):\n",
    "      cur_label = torch.Tensor(target_ids[j])\n",
    "      hidden_state,decoder_output = dec(context, prev_hidden_state, cur_label)\n",
    "      prev_hidden_state = hidden_state\n",
    "      prev_label = torch.argmax(decoder_output)\n",
    "      decoder_outputs.append(decoder_output)\n",
    "    decoder_outputs = torch.cat(decoder_outputs, dim=0)\n",
    "    #print(\"=======================\")\n",
    "    #print(decoder_outputs.size(), labels.size())\n",
    "    #print(target_ids, torch.argmax(decoder_outputs, dim=-1),  labels)\n",
    "    #print(\"=======================\")\n",
    "    #print(decoder_outputs.size(), labels.size())\n",
    "    # if i % 1000==0:\n",
    "    #   print(torch.gather(decoder_outputs, -1, labels.unsqueeze(dim=-1)))\n",
    "    loss += loss_fn(decoder_outputs, labels)\n",
    "    #loss.backward()\n",
    "    # print(\"========BEFORE STEP\")\n",
    "    # print(enc.GRU.weight_ih_l0[280,50], enc.GRU.weight_ih_l0.grad[280,50])\n",
    "    # print(dec.GRU.weight_ih_l0[280,50], dec.GRU.weight_ih_l0.grad[280,50])\n",
    "    # if i%1000==0:\n",
    "    #   print(hidden_state)\n",
    "    # max_grad = torch.max(dec.dense_layer.weight.grad)\n",
    "    # max_grad_pos = (dec.dense_layer.weight.grad==max_grad).nonzero()\n",
    "    # max_grad_x = int(max_grad_pos[0][0])\n",
    "    # max_grad_y = int(max_grad_pos[0][1])\n",
    "    # print(dec.dense_layer.weight[max_grad_x,max_grad_y],dec.dense_layer.weight.grad[max_grad_x,max_grad_y], max_grad, max_grad_pos[0])\n",
    "    # encoder_optimizer.step()\n",
    "    # decoder_optimizer.step()\n",
    "    # print(\"========AFTER STEP\")\n",
    "    # print(enc.GRU.weight_ih_l0[280,50], enc.GRU.weight_ih_l0.grad[280,50])\n",
    "    # print(dec.GRU.weight_ih_l0[280,50], dec.GRU.weight_ih_l0.grad[280,50])\n",
    "    # print(dec.dense_layer.weight[max_grad_x,max_grad_y],dec.dense_layer.weight.grad[max_grad_x,max_grad_y], max_grad, max_grad_pos[0])\n",
    "    if (i+1) % batch_size == 0:\n",
    "      running_loss += loss\n",
    "      loss.backward()\n",
    "      # print(\"========BEFORE STEP\")\n",
    "      # print(enc.GRU.weight_ih_l0[280,50], enc.GRU.weight_ih_l0.grad[280,50])\n",
    "      # print(dec.GRU.weight_ih_l0[280,50], dec.GRU.weight_ih_l0.grad[280,50])\n",
    "      encoder_optimizer.step()\n",
    "      decoder_optimizer.step()\n",
    "      # print(\"========AFTER STEP\")\n",
    "      # print(enc.GRU.weight_ih_l0[280,50], enc.GRU.weight_ih_l0.grad[280,50])\n",
    "      # print(dec.GRU.weight_ih_l0[280,50], dec.GRU.weight_ih_l0.grad[280,50])\n",
    "      encoder_optimizer.zero_grad()\n",
    "      decoder_optimizer.zero_grad()\n",
    "      if batch_num%100==0:\n",
    "        batch_end_time = time.time()\n",
    "        batch_total_time = batch_end_time-batch_start_time\n",
    "        print(f\"End of batch {batch_num}, current loss is {loss/batch_size}, total time taken: {batch_total_time/60}\")\n",
    "      print(f\"Finished batch {batch_num} in time {(time.time()-cur_batch_start_time)/60} minutes\")\n",
    "      cur_batch_start_time = time.time()\n",
    "      loss = 0\n",
    "      batch_num +=1\n",
    "  running_loss += loss\n",
    "  loss.backward()\n",
    "  encoder_optimizer.step()\n",
    "  decoder_optimizer.step()\n",
    "  epoch_end_time = time.time()\n",
    "  epoch_total_time = epoch_end_time-epoch_start_time\n",
    "  print(f\"End of epoch {epoch}, current loss is {running_loss/len(train_ds)}, total time taken: {epoch_total_time/60}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7Cjjo8RxBU5n"
   },
   "outputs": [],
   "source": [
    "class LuongAttnDecoder(nn.Module):\n",
    "  def __init__(self, emb_dim, enc_hidden_dim, dec_hidden_dim, fr_token_vectors, train_emb=False):\n",
    "    super().__init__()\n",
    "    self.embedding_layer = nn.Embedding.from_pretrained(fr_token_vectors)\n",
    "    if not train_emb:\n",
    "      self.embedding_layer.weight.requires_grad = False\n",
    "    self.GRU = nn.GRU(emb_dim, dec_hidden_dim)\n",
    "    self.dense_layer = nn.Linear(dec_hidden_dim+enc_hidden_dim, len(fr_token_vectors))\n",
    "    self.attn = nn.Linear(enc_hidden_dim, enc_hidden_dim)\n",
    "    self.softmax_layer = nn.Softmax(dim=-1)\n",
    "  def forward(self, context_vectors, init_hidden_state, targets):\n",
    "    x = self.embedding_layer(targets)\n",
    "    _, hidden = self.GRU(x.unsqueeze(dim=0), init_hidden_state)\n",
    "    context_vector_lin_out = self.attn(context_vectors)\n",
    "    alignment_scores = context_vector_lin_out @ hidden.T\n",
    "    context_vector = alignment_scores.T @ context_vectors\n",
    "    x = torch.tanh(self.dense_layer(torch.cat([context_vector, hidden], dim=1)))\n",
    "    x = self.softmax_layer(x)\n",
    "    return hidden,x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TCz3cecmXeF4"
   },
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "  def __init__(self,emb_dim,n_heads):\n",
    "    super().__init__()\n",
    "    self.emb_dim = emb_dim\n",
    "    self.n_heads = n_heads\n",
    "    self.heads = []\n",
    "    self.head_size = self.emb_dim/self.n_heads\n",
    "    for i in torch.range(self.n_heads):\n",
    "      cur_heads = [nn.Linear(self.emb_dim,self.head_size)]*3\n",
    "      self.heads.append(cur_heads)\n",
    "    self.softmax_layer = nn.Softmax(dim=-1)\n",
    "    self.output_linear_layer = nn.Linear(emb_dim,emb_dim)\n",
    "  def forward(self, Q, K, V, attn_mask):\n",
    "    head_outputs = []\n",
    "    for head in self.heads:\n",
    "      Q_attn = self.head[0](Q)\n",
    "      K_attn = self.head[1](K)\n",
    "      V_attn = self.head[2](V)\n",
    "      attn_scores = self.softmax_layer(((Q_attn @ K_attn.T) + attn_mask)/torch.sqrt(Q.size()[-1]))\n",
    "      head_output = attn_scores @ V_attn\n",
    "      head_outputs.append(head_output)\n",
    "    head_result = torch.cat(head_outputs, dim=-1)\n",
    "    x = self.output_linear_layer(head_result)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oDFuDJyjcDVt"
   },
   "outputs": [],
   "source": [
    "class PosEncoding(nn.Module):\n",
    "  def __init__(self, n, d):\n",
    "    super().__init__()\n",
    "    self.n = n\n",
    "    self.d = d\n",
    "  def pos_encoding_denom(self,i):\n",
    "    return self.n**(2*i/self.d)\n",
    "  def forward(self, inputs):\n",
    "    x_k = torch.arange(inputs.size()[0]).unsqueeze(dim=-1)\n",
    "    x_k = x_k.expand(-1,self.emb_dim)\n",
    "    x_i = torch.arange(inputs.size()[1]).unsqueeze(dim=0)\n",
    "    x_i = torch.Tensor(list(map(self.pos_encoding_denom, torch.arange(inputs.size()[1])))).unsqueeze(dim=0)\n",
    "    x_i = x_i.expand(inputs.size()[0],-1)\n",
    "    x_pos = x_k/x_i\n",
    "    even_indices = torch.arange(0,inputs.size()[1], step=2)\n",
    "    odd_indices = torch.arange(1,inputs.size()[1], step=2)\n",
    "    x_pos[:,even_indices] = torch.sin(x_pos[:,even_indices])\n",
    "    x_pos[:,odd_indices] = torch.cos(x_pos[:,odd_indices])\n",
    "    return inputs+x_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T9X9x7qAM27j"
   },
   "outputs": [],
   "source": [
    "class AttnEncoder(nn.Module):\n",
    "  def __init__(self, emb_dim):\n",
    "    super().__init__()\n",
    "    self.emb_dim = emb_dim\n",
    "    self.pos_encoding = PosEncoding(10000,emb_dim)\n",
    "    self.multi_head_attn = nn.MultiheadAttention(emb_dim, 3)\n",
    "    self.layer_norm1 = nn.LayerNorm(emb_dim)\n",
    "    self.linear_layer = nn.Linear(emb_dim, emb_dim)\n",
    "    self.relu = nn.ReLU()\n",
    "    self.layer_norm2 = nn.LayerNorm(emb_dim)\n",
    "  def forward(self, inputs):\n",
    "    inputs = self.pos_encoding(inputs)\n",
    "    x = self.multi_head_attn(inputs, inputs, inputs)[0]\n",
    "    x = self.layer_norm1(inputs+x)\n",
    "    linear_output = self.linear_layer(x)\n",
    "    feed_forward_output = self.relu(linear_output)\n",
    "    x = self.layer_norm2(feed_forward_output+x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 131
    },
    "id": "vkuYARnbb37O",
    "outputId": "dbca9df2-893b-43ee-8cf7-ee7552c43976"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-65-bdf39958fd34>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    def __init__(self, ):\u001b[0m\n\u001b[0m                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "class AttnDecoder(nn.Module):\n",
    "  def __init__(self, emb_dim, encoder_output):\n",
    "    self.emb_dim = emb_dim\n",
    "    self.encoder_output = encoder_output\n",
    "    self.pos_encoding = PosEncoding(10000,emb_dim)\n",
    "    self.masked_multi_head_attn = nn.MultiheadAttention(emb_dim, 3)\n",
    "    self.layer_norm1 = nn.LayerNorm(emb_dim)\n",
    "    self.encoder_decoder_attn = nn.MultiheadAttention(emb_dim, 3)\n",
    "    self.layer_norm2 = nn.LayerNorm(emb_dim)\n",
    "    self.linear_layer1 = nn.Linear(emb_dim, emb_dim)\n",
    "    self.relu = nn.ReLU()\n",
    "    self.layer_norm3 = nn.LayerNorm(emb_dim)\n",
    "    self.linear_layer2 = nn.Linear(emb_dim)\n",
    "  def forward(self, inputs, attn_mask, timestep):\n",
    "    inputs = self.pos_encoding(inputs)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "unFsAGeyS6X9",
    "outputId": "764f2bce-23c5-4d85-bf93-36fbcbd86715"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 300])\n"
     ]
    }
   ],
   "source": [
    "attn_enc = AttnEncoder(300)\n",
    "x = attn_enc(torch.randn(10,300))\n",
    "print(x.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZHce0qHXEHdz",
    "outputId": "0e9a7093-59ae-481b-ca1c-0d6217855a1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 896])\n"
     ]
    }
   ],
   "source": [
    "emb_dim = 300\n",
    "enc_hidden_dim = 128\n",
    "dec_hidden_dim = 128\n",
    "enc = Encoder(emb_dim, enc_hidden_dim, en_token_vectors)\n",
    "dec = LuongAttnDecoder(emb_dim, enc_hidden_dim, dec_hidden_dim, fr_token_vectors)\n",
    "for i in range(1):\n",
    "    inputs = train_ds[i]['input_ids']\n",
    "    target_ids = train_ds[i]['target_ids']\n",
    "    labels = train_ds[i]['labels']\n",
    "    inputs = inputs.to(device)\n",
    "    target_ids = target_ids.to(device)\n",
    "    labels = labels.to(device)\n",
    "    outputs, context = enc(inputs)\n",
    "    prev_hidden_state = context\n",
    "    prev_label = None\n",
    "    decoder_outputs = []\n",
    "    for j in range(1):\n",
    "      cur_label = torch.Tensor(target_ids[j])\n",
    "      hidden_state,decoder_output = dec(outputs, prev_hidden_state, cur_label)\n",
    "      print(decoder_output.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O8OO0Ok2bytY"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "encoder_decoder_base_env",
   "language": "python",
   "name": "encoder_decoder_base_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "006484782ba94061a8f72f83404cde81": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fe79a96de1fe401abfc4f1123e534df4",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_7d9b9e7cc5bf4129b894a81b69a727e2",
      "value": 1
     }
    },
    "124914b851fe416da26522f55cbbc673": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4af04500687242d3aa1dc0043e64baf6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4b01f797a65b4a008d3328b54122fc73": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "513b1a4b41fd47b3879935517946c785": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_be911d03968f4d7f97a85b905f4804da",
      "placeholder": "​",
      "style": "IPY_MODEL_ac5ff9a28e8949218d7b78a168feeb0e",
      "value": "100%"
     }
    },
    "7d9b9e7cc5bf4129b894a81b69a727e2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "8fee3868a1554cad869322a25e136477": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4b01f797a65b4a008d3328b54122fc73",
      "placeholder": "​",
      "style": "IPY_MODEL_4af04500687242d3aa1dc0043e64baf6",
      "value": " 1/1 [00:00&lt;00:00, 14.84it/s]"
     }
    },
    "ac5ff9a28e8949218d7b78a168feeb0e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b4a11482756b472182a81f5c418e72af": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_513b1a4b41fd47b3879935517946c785",
       "IPY_MODEL_006484782ba94061a8f72f83404cde81",
       "IPY_MODEL_8fee3868a1554cad869322a25e136477"
      ],
      "layout": "IPY_MODEL_124914b851fe416da26522f55cbbc673"
     }
    },
    "be911d03968f4d7f97a85b905f4804da": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fe79a96de1fe401abfc4f1123e534df4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
